<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="Pre-prepation如何进行学习 本次航行依然采用github开源教程学习+明确时间任务打卡+讨论交流+直播答疑的形式，欢迎大家踊跃提出自己的问题和看法！ 鼓励各位小伙伴通过组队的形式共同学习，互相交流，互相督促，共同进步，组队的人数为[5-10人] 如何完成作业  每个任务都需要使用Datawhale小程序进行作业打卡，每位同学需要在打卡截止时间前完成作业并打卡，否则会被【抱出群】哦。 任">
<meta property="og:type" content="article">
<meta property="og:title" content="Notes-EnsembleLearning">
<meta property="og:url" content="http://example.com/2021/05/10/Notes-EnsembleLearning/index.html">
<meta property="og:site_name" content="Yang Jing">
<meta property="og:description" content="Pre-prepation如何进行学习 本次航行依然采用github开源教程学习+明确时间任务打卡+讨论交流+直播答疑的形式，欢迎大家踊跃提出自己的问题和看法！ 鼓励各位小伙伴通过组队的形式共同学习，互相交流，互相督促，共同进步，组队的人数为[5-10人] 如何完成作业  每个任务都需要使用Datawhale小程序进行作业打卡，每位同学需要在打卡截止时间前完成作业并打卡，否则会被【抱出群】哦。 任">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://img-blog.csdnimg.cn/2019052109512454.png?x-oss-process=image/watermark%EF%BC%8Ctype_ZmFuZ3poZW5naGVpdGk%EF%BC%8Cshadow_10%EF%BC%8Ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzM1ODIxOTc2%EF%BC%8Csize_16%EF%BC%8Ccolor_FFFFFF%EF%BC%8Ct_70">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNgy1gqdgrptfccj310g0u0wlt.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNgy1gqdgkxwin8j30yk0u011n.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNgy1gqgtctlreej3101092tb1.jpg">
<meta property="article:published_time" content="2021-05-10T12:40:02.000Z">
<meta property="article:modified_time" content="2022-01-03T06:34:42.932Z">
<meta property="article:author" content="yangjing">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/2019052109512454.png?x-oss-process=image/watermark%EF%BC%8Ctype_ZmFuZ3poZW5naGVpdGk%EF%BC%8Cshadow_10%EF%BC%8Ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzM1ODIxOTc2%EF%BC%8Csize_16%EF%BC%8Ccolor_FFFFFF%EF%BC%8Ct_70">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.jpg">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/favicon.jpg" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.jpg">
        
      
    
    <!-- title -->
    <title>Notes-EnsembleLearning</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
      <link rel="alternate" href="/true" title="Yang Jing" type="application/atom+xml" />
    
	<!-- mathjax -->
	
		<script type="text/x-mathjax-config">
		  MathJax.Hub.Config({
			tex2jax: {
			  skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
			  inlineMath: [['$','$']]
			}
		  });
		</script>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
	
<meta name="generator" content="Hexo 6.0.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a href="/recording/">Recording</a></li><!--
     --><!--
       --><li><a href="/links/">Links</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post" href="/2021/06/01/Paper-FewShotNER/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Next post" href="/2021/03/21/Paper-GraphEmbedding/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2021/05/10/Notes-EnsembleLearning/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2021/05/10/Notes-EnsembleLearning/&text=Notes-EnsembleLearning"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2021/05/10/Notes-EnsembleLearning/&title=Notes-EnsembleLearning"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2021/05/10/Notes-EnsembleLearning/&is_video=false&description=Notes-EnsembleLearning"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Notes-EnsembleLearning&body=Check out this article: http://example.com/2021/05/10/Notes-EnsembleLearning/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2021/05/10/Notes-EnsembleLearning/&title=Notes-EnsembleLearning"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2021/05/10/Notes-EnsembleLearning/&title=Notes-EnsembleLearning"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2021/05/10/Notes-EnsembleLearning/&title=Notes-EnsembleLearning"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2021/05/10/Notes-EnsembleLearning/&title=Notes-EnsembleLearning"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2021/05/10/Notes-EnsembleLearning/&name=Notes-EnsembleLearning&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2021/05/10/Notes-EnsembleLearning/&t=Notes-EnsembleLearning"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Pre-prepation"><span class="toc-number">1.</span> <span class="toc-text">Pre-prepation</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Voting-amp-Bagging"><span class="toc-number">2.</span> <span class="toc-text">Voting &amp; Bagging</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Voting-%E6%8A%95%E7%A5%A8%E6%B3%95"><span class="toc-number">2.0.1.</span> <span class="toc-text">Voting 投票法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Bagging-%E8%87%AA%E5%8A%A9%E9%87%87%E6%A0%B7%E6%B3%95"><span class="toc-number">2.0.2.</span> <span class="toc-text">Bagging 自助采样法</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Boosting"><span class="toc-number">3.</span> <span class="toc-text">Boosting</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Concepts"><span class="toc-number">3.0.1.</span> <span class="toc-text">Concepts</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AdaBoost"><span class="toc-number">3.0.2.</span> <span class="toc-text">AdaBoost</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#XGBoost"><span class="toc-number">3.0.3.</span> <span class="toc-text">XGBoost</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#LightGBM"><span class="toc-number">3.0.4.</span> <span class="toc-text">LightGBM</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conlusion"><span class="toc-number">3.0.5.</span> <span class="toc-text">Conlusion</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Reference"><span class="toc-number">3.0.6.</span> <span class="toc-text">Reference</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Blending"><span class="toc-number">4.</span> <span class="toc-text">Blending</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Concept"><span class="toc-number">4.0.1.</span> <span class="toc-text">Concept</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Algorithms"><span class="toc-number">4.0.2.</span> <span class="toc-text">Algorithms</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Blending-Example"><span class="toc-number">4.0.3.</span> <span class="toc-text">Blending Example</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusion"><span class="toc-number">4.0.4.</span> <span class="toc-text">Conclusion</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Tutorial"><span class="toc-number">4.0.5.</span> <span class="toc-text">Tutorial</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Stacking"><span class="toc-number">5.</span> <span class="toc-text">Stacking</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Concept-1"><span class="toc-number">5.0.1.</span> <span class="toc-text">Concept</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Algorithm"><span class="toc-number">5.0.2.</span> <span class="toc-text">Algorithm</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Stacking-Example"><span class="toc-number">5.0.3.</span> <span class="toc-text">Stacking Example</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#mxtend-%E5%B7%A5%E5%85%B7%E5%8C%85-link"><span class="toc-number">5.0.4.</span> <span class="toc-text">mxtend 工具包 link</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sklearn%E4%B9%8B%E8%B0%83%E5%8F%82%E6%96%B9%E6%B3%95GridSearchCV-%E4%BB%A5%E5%8F%8A-cross-val-score"><span class="toc-number">5.0.5.</span> <span class="toc-text">sklearn之调参方法GridSearchCV 以及 cross_val_score</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sklearn%E4%B9%8B%E8%B0%83%E5%8F%82%E6%96%B9%E6%B3%95-%E8%B4%9D%E5%8F%B6%E6%96%AFbayes-opt"><span class="toc-number">5.0.6.</span> <span class="toc-text">sklearn之调参方法 -贝叶斯bayes_opt</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sklearn%E7%9A%84roc-auc%E6%9B%B2%E7%BA%BF%E7%BB%98%E5%88%B6"><span class="toc-number">5.0.7.</span> <span class="toc-text">sklearn的roc_auc曲线绘制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusion-1"><span class="toc-number">5.0.8.</span> <span class="toc-text">Conclusion</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Tutorial-1"><span class="toc-number">5.0.9.</span> <span class="toc-text">Tutorial</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%A1%88%E4%BE%8B%E4%B8%80-%EF%BC%88%E5%B9%B8%E7%A6%8F%E6%84%9F%E9%A2%84%E6%B5%8B%EF%BC%89"><span class="toc-number">6.</span> <span class="toc-text">集成学习案例一 （幸福感预测）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Step1"><span class="toc-number">6.0.1.</span> <span class="toc-text">Step1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#step2"><span class="toc-number">6.0.2.</span> <span class="toc-text">step2</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Step3"><span class="toc-number">6.0.3.</span> <span class="toc-text">Step3</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Step4"><span class="toc-number">6.0.4.</span> <span class="toc-text">Step4</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#lightgbm-%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%82%E6%95%B0%E4%BF%9D%E5%AD%98"><span class="toc-number">6.0.5.</span> <span class="toc-text">lightgbm 模型的参数保存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Step5-Ensemble"><span class="toc-number">6.0.6.</span> <span class="toc-text">Step5 Ensemble</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Reference-1"><span class="toc-number">6.0.7.</span> <span class="toc-text">Reference</span></a></li></ol></li></ol></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        Notes-EnsembleLearning
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">yangjing</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2021-05-10T12:40:02.000Z" itemprop="datePublished">2021-05-10</time>
        
        (Updated: <time datetime="2022-01-03T06:34:42.932Z" itemprop="dateModified">2022-01-03</time>)
        
      
    </div>


      
    <div class="article-category">
        <i class="fas fa-archive"></i>
        <a class="category-link" href="/categories/Notes/">Notes</a>
    </div>


      

    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <h1 id="Pre-prepation"><a href="#Pre-prepation" class="headerlink" title="Pre-prepation"></a>Pre-prepation</h1><p>如何进行学习</p>
<p>本次航行依然采用github开源教程学习+明确时间任务打卡+讨论交流+直播答疑的形式，欢迎大家踊跃提出自己的问题和看法！ 鼓励各位小伙伴通过组队的形式共同学习，互相交流，互相督促，共同进步，组队的人数为[5-10人]</p>
<p>如何完成作业</p>
<ul>
<li>每个任务都需要使用Datawhale小程序进行作业打卡，每位同学需要在打卡截止时间前完成作业并打卡，否则会被【抱出群】哦。</li>
<li>任选CSDN、Github（经常打不开，不建议使用）、简书、B站等平台，将自己的学习体会，输出成学习分享后，将分享的链接，填至小程序的 “打卡链接” 中相应的位置。</li>
<li>打卡包括但不限于对理论知识的理解、扩展、代码实现、公式推导等等，也可直播分享自己的学习过程。不需要全篇复制粘贴教程原文。如果笔记中需要引用教程内容或其它资料，希望注明出处，并附上来源链接，避免版权纠纷。</li>
<li>水卡（字数少于50、与本任务内容无关、全文复制粘贴、大纲复制粘贴等）和空白打卡、错误链接等将被视为未打卡，抱出群并关闭后续打卡。若有因为链接打不开等问题被误抱出群，可以联系助教说明情况。</li>
</ul>
<p>优秀学员的评价标准包括但不限于作业质量和群内学习答疑两个方面，欢迎大家积极表现出自己的优秀特质！</p>
<p>开源项目地址： <a target="_blank" rel="noopener" href="https://github.com/datawhalechina/team-learning-data-mining/tree/master/EnsembleLearning">datawhalechina/team-learning-data-mining</a></p>
<h1 id="Voting-amp-Bagging"><a href="#Voting-amp-Bagging" class="headerlink" title="Voting &amp; Bagging"></a>Voting &amp; Bagging</h1><h3 id="Voting-投票法"><a href="#Voting-投票法" class="headerlink" title="Voting 投票法"></a>Voting 投票法</h3><ul>
<li>根据是否考虑概率可分为：软投票和硬投票<ul>
<li>硬投票：预测结果是所有投票结果最多出现的类。</li>
<li>软投票：预测结果是所有投票结果中概率加和最大的类</li>
</ul>
</li>
<li>根据对于基学习器结果的处理： 回归投票和 分类投票<ul>
<li>回归投票法：预测结果是所有模型预测结果的平均值。</li>
<li>分类投票法：预测结果是所有模型种出现最多的预测结果。</li>
</ul>
</li>
<li>最终投票的结果与基学习器的性能的好坏有十分密切的关系，而且在选取基学习器(svm， lr， decision tree， gbdt)时候有以下的两条原则。<ul>
<li>基模型之间的效果不能差别过大。当某个基模型相对于其他基模型效果过差时，该模型很可能成为噪声。</li>
<li>基模型之间应该有较小的同质性。例如在基模型预测效果近似的情况下，基于树模型与线性模型的投票，往往优于两个树模型或两个线性模型。</li>
</ul>
</li>
</ul>
<h3 id="Bagging-自助采样法"><a href="#Bagging-自助采样法" class="headerlink" title="Bagging 自助采样法"></a>Bagging 自助采样法</h3><ul>
<li>由于简单的投票法只是最后一个简单的统计，过于的简单，我们的想法是：不仅仅集成最后的预测的结果，同时采用一定的策略来影响基学习器的训练？</li>
<li>**自助采样(bootstrap)**即有放回的从数据集中进行采样，也就是说，同样的一个样本可能被多次进行采样。一个自助采样的小例子是我们希望估计全国所有人口年龄的平均值，那么我们可以在全国所有人口中随机抽取不同的集合（这些集合可能存在交集，计算每个集合的平均值，然后将所有平均值的均值作为估计值</li>
<li>Bagging方法之所以有效，是因为每个模型都是在略微不同的训练数据集上拟合完成的，这又使得每个基模型之间存在略微的差异，使每个基模型拥有略微不同的训练能力</li>
</ul>
<h1 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h1><h3 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a>Concepts</h3><ul>
<li>强学习器 vs 弱学习器<ul>
<li>弱学习：识别错误率小于1/2（即准确率仅比随机猜测略高的学习算法） </li>
<li>强学习：识别准确率很高并能在多项式时间内完成的学习算法</li>
<li>在PAC 学习的框架下，强可学习和弱可学习是等价的，也就是说一个概念是强可学习的充分必要条件是这个概念是弱可学习的</li>
</ul>
</li>
<li>如何能够将弱学习器组合得到强学习器<ul>
<li>第一个是每一轮学习应该如何改变数据的概率分布？</li>
<li>第二个是如何将各个弱分类器组合起来 ？</li>
</ul>
</li>
</ul>
<h3 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h3><ul>
<li>提高那些被前一轮分类器错误分类的样本的权重，而降低那些被正确分类的样本的权重。这样一来，那些在上一轮分类器中没有得到正确分类的样本，由于其权重的增大而在后一轮的训练中“备受关注”。</li>
<li>各个弱分类器的组合是通过采取加权多数表决的方式，具体来说，加大分类错误率低的弱分类器的权重。</li>
</ul>
<p>感觉到很多知识都忘记了，回顾李航《统计学习方法》的相关内容</p>
<h3 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h3><ul>
<li><a target="_blank" rel="noopener" href="https://xgboost.readthedocs.io/en/latest/parameter.html">参数解读</a></li>
<li>XGBoost Python 更多精彩案例： <a target="_blank" rel="noopener" href="https://github.com/dmlc/xgboost/tree/master/demo/guide-python">https://github.com/dmlc/xgboost/tree/master/demo/guide-python</a></li>
</ul>
<p>XGBoost调参（结合sklearn网格搜索）<br>代码参考：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/1100e333fcab">https://www.jianshu.com/p/1100e333fcab</a></p>
<h3 id="LightGBM"><a href="#LightGBM" class="headerlink" title="LightGBM"></a>LightGBM</h3><p><strong>LightGBM与网格搜索结合调参：</strong><br>参考代码：<a target="_blank" rel="noopener" href="https://blog.csdn.net/u012735708/article/details/83749703">https://blog.csdn.net/u012735708/article/details/83749703</a></p>
<h3 id="Conlusion"><a href="#Conlusion" class="headerlink" title="Conlusion"></a>Conlusion</h3><p>梯度提升和梯度下降的区别？</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/67186694">梯度下降和梯度提升(Gradient Boosting)</a></p>
</li>
<li><p>code（<a target="_blank" rel="noopener" href="https://github.com/FernandoLpz/Stacking-Blending-Voting-Ensembles">https://github.com/FernandoLpz/Stacking-Blending-Voting-Ensembles</a>)</p>
</li>
</ul>
<h1 id="Blending"><a href="#Blending" class="headerlink" title="Blending"></a>Blending</h1><h3 id="Concept"><a href="#Concept" class="headerlink" title="Concept"></a>Concept</h3><p>什么是集成学习，有何优点？</p>
<ul>
<li>集成学习能够通过对于多个“弱学习器” (回归模型/分类模型)结合来完成学习任务，通常能够取得比单个学习器更加优异的效果。</li>
<li>集成学习最大的优点是：有效的防止过拟合和欠拟合的问题（我们可以从方差-偏差，间隔理论等方面进行分析）</li>
</ul>
<p>集成学习分类(代表算法)以及分类的标准和依据是什么？</p>
<ul>
<li>Bagging： Random Forest</li>
<li><em>Boosting</em>： Adaboost， xgboost</li>
<li>Stacking：</li>
<li>Stacking Generalization 方法是其中关键是降低不同学习机器（即ML模型）的泛化误差。 Stacking Generalization方法的总体思想是生成元模型( meta-model)，这种元模型是通过k倍交叉验证由一组弱学习器的预测组成的。 最后，使用额外一个学习器（通常称为“最终估计器”或“最终学习者”）对元模型进行训练。</li>
</ul>
<p>这里单独的将 Stacking 和bagging/boosting放到一起并列；<strong>Voting</strong> 投票法可以看作是 bagging方法的补充 ，Blending 可以看作是一种特殊的 Stacking 方法。</p>
<h3 id="Algorithms"><a href="#Algorithms" class="headerlink" title="Algorithms"></a>Algorithms</h3><p>Blending相较于Stacking来说要简单一些，其流程大致分为以下几步：</p>
<ul>
<li>将数据划分为训练集和测试集(test_set)，其中训练集需要再次划分为训练集(train_set)和验证集(val_set)， 创建第一层的多个模型，这些模型可以使同质的也可以是异质的；</li>
<li>使用train_set训练步骤2中的多个模型，然后用训练好的模型预测val_set和test_set得到val_predict， test_predict1；</li>
<li>创建第二层的模型，使用val_predict作为训练集训练第二层的模型；使用第二层训练好的模型对第二层测试集test_predict1进行预测，该结果为整个测试集的结果</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/2019052109512454.png?x-oss-process=image/watermark%EF%BC%8Ctype_ZmFuZ3poZW5naGVpdGk%EF%BC%8Cshadow_10%EF%BC%8Ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzM1ODIxOTc2%EF%BC%8Csize_16%EF%BC%8Ccolor_FFFFFF%EF%BC%8Ct_70" alt="https://img-blog.csdnimg.cn/2019052109512454.png?x-oss-process=image/watermark，type_ZmFuZ3poZW5naGVpdGk，shadow_10，text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzM1ODIxOTc2，size_16，color_FFFFFF，t_70"></p>
<p>在下图之中，我们可以看到使用3个基本模型（弱学习器）和最终分类器的Blending体系结构。 蓝色框代表训练数据中用于生成预测以形成元模型的那部分（黄色框)。 绿色框代表测试数据，用于生成预测以形成元模型测试数据（紫色框）</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gqdgrptfccj310g0u0wlt.jpg" alt="https://tva1.sinaimg.cn/large/008i3skNgy1gqdgrptfccj310g0u0wlt.jpg"></p>
<p>from <a target="_blank" rel="noopener" href="https://towardsdatascience.com/ensemble-learning-Stacking-blending-voting-b37737c4f483">https://towardsdatascience.com/ensemble-learning-Stacking-blending-voting-b37737c4f483</a></p>
<h3 id="Blending-Example"><a href="#Blending-Example" class="headerlink" title="Blending Example"></a>Blending Example</h3><ul>
<li>完整代码：<a target="_blank" rel="noopener" href="https://github.com/FernandoLpz/Stacking-Blending-Voting-Ensembles/blob/master/blending.py">https://github.com/FernandoLpz/Stacking-Blending-Voting-Ensembles/blob/master/blending.py</a></li>
</ul>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><ul>
<li>Blending 和 Stacking 的核心的区别是什么？<ul>
<li>在于对数据集的使用，blending使用的是留一法，二Stacking使用的是k-fold交叉验证</li>
</ul>
</li>
<li>Blending 的最大的缺点是是什么？<ul>
<li>blending只使用了一部分数据集作为留出集进行验证，也就是只能用上数据中的一部分，实际上这对数据来说是很奢侈浪费的。</li>
<li>改进的方法：在训练meta-model的时候进行k-fold 交叉验证充分利用全部的数据。</li>
</ul>
</li>
</ul>
<h3 id="Tutorial"><a href="#Tutorial" class="headerlink" title="Tutorial"></a>Tutorial</h3><ul>
<li>DataWhale: <a target="_blank" rel="noopener" href="https://nbviewer.jupyter.org/github/datawhalechina/team-learning-data-mining/blob/master/EnsembleLearning/CH5-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E4%B9%8Bblending%E4%B8%8EStacking/Stacking.ipynb">LINK</a></li>
<li><a target="_blank" rel="noopener" href="https://towardsdatascience.com/ensemble-learning-Stacking-blending-voting-b37737c4f483">Ensemble Learning: Stacking， Blending &amp; Voting</a></li>
<li><a target="_blank" rel="noopener" href="https://machinelearningmastery.com/blending-ensemble-machine-learning-with-python/">Blending Ensemble Machine Learning With Python</a></li>
<li><a target="_blank" rel="noopener" href="https://www.mygreatlearning.com/blog/ensemble-learning/">Ensemble learning with Stacking and Blending</a></li>
</ul>
<h1 id="Stacking"><a href="#Stacking" class="headerlink" title="Stacking"></a>Stacking</h1><h3 id="Concept-1"><a href="#Concept-1" class="headerlink" title="Concept"></a>Concept</h3><ul>
<li>根据集成学习每个弱学习如何进行集成的策略的不同，我们可以根据结合策略大致分成三种<ul>
<li>平均法： 简单平均， 加权平均</li>
<li>voting 投票法: 绝对多数投票法；相对多数投票法；加权投票法</li>
<li>Stacking 学习法：Layer0[base-learner]+Layer1[meta-learner]</li>
</ul>
</li>
<li>Stacking 先从初始数据训练处初级学习器，然后“生成”一个新的数据集用于训练次级学习器</li>
</ul>
<h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gqdgkxwin8j30yk0u011n.jpg" alt="https://tva1.sinaimg.cn/large/008i3skNgy1gqdgkxwin8j30yk0u011n.jpg"></p>
<p>From <a target="_blank" rel="noopener" href="https://towardsdatascience.com/ensemble-learning-Stacking-blending-voting-b37737c4f483">https://towardsdatascience.com/ensemble-learning-Stacking-blending-voting-b37737c4f483</a></p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gqgtctlreej3101092tb1.jpg" alt="https://tva1.sinaimg.cn/large/008i3skNgy1gqgtctlreej3101092tb1.jpg"></p>
<h3 id="Stacking-Example"><a href="#Stacking-Example" class="headerlink" title="Stacking Example"></a>Stacking Example</h3><ul>
<li>完整代码：<a target="_blank" rel="noopener" href="https://github.com/FernandoLpz/Stacking-Blending-Voting-Ensembles/blob/master/Stacking.py">https://github.com/FernandoLpz/Stacking-Blending-Voting-Ensembles/blob/master/Stacking.py</a></li>
</ul>
<h3 id="mxtend-工具包-link"><a href="#mxtend-工具包-link" class="headerlink" title="mxtend 工具包 link"></a>mxtend 工具包 <a target="_blank" rel="noopener" href="http://rasbt.github.io/mlxtend/">link</a></h3><ul>
<li>功能<ul>
<li>作为sklearn的拓展，plot_decision_regions能够十分方便的画出决策边界 (不用np.contour)，<a target="_blank" rel="noopener" href="http://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/#example-1-decision-regions-in-2d">example</a></li>
<li>在画出边界的同时能够，简单清晰明了的hight_X_test</li>
<li>关于超过两个特征的数据 filler_feature_values：<a target="_blank" rel="noopener" href="http://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/#example-7-decision-regions-with-more-than-two-training-features">example7</a></li>
</ul>
</li>
</ul>
<h3 id="sklearn之调参方法GridSearchCV-以及-cross-val-score"><a href="#sklearn之调参方法GridSearchCV-以及-cross-val-score" class="headerlink" title="sklearn之调参方法GridSearchCV 以及 cross_val_score"></a>sklearn之调参方法GridSearchCV 以及 cross_val_score</h3><ul>
<li><p>功能</p>
<ul>
<li>cross_val_score(clf= ， X= ， y = ， cv = ) : 一般用于获取每折的交叉验证的得分 可以返回 score.mean() ， score.std()作为直接的指标 <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py">example</a></li>
<li>GridSearchCV (clf= ， params_dict = ，scoring) : 最重要的是在于param_dict 的设置， 可以返回grid.best_param_ 以及 grid_best_scores_</li>
</ul>
<p>  <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html?highlight=cross_val_score#sklearn.model_selection.cross_val_score">sklearn.model_selection.cross_val_score - scikit-learn 0.24.2 documentation</a></p>
<ul>
<li></li>
</ul>
<p>  <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearch#sklearn.model_selection.GridSearchCV">sklearn.model_selection.GridSearchCV - scikit-learn 0.24.2 documentation</a></p>
</li>
</ul>
<h3 id="sklearn之调参方法-贝叶斯bayes-opt"><a href="#sklearn之调参方法-贝叶斯bayes-opt" class="headerlink" title="sklearn之调参方法 -贝叶斯bayes_opt"></a>sklearn之调参方法 -贝叶斯bayes_opt</h3><p>功能：贝叶斯调参工具包 [bayes_opt ] </p>
<p><a target="_blank" rel="noopener" href="https://github.com/fmfn/BayesianOptimization/blob/master/examples/basic-tour.ipynb">fmfn/BayesianOptimization</a></p>
<ul>
<li>pip install bayesian-optimization</li>
<li>功能: 相比于gridsearchcv 的暴力搜索，贝叶斯调参利用高斯过程引入了先验信息，能够更加快速的求解最优参数，此外贝叶斯方法对于非凸优化求解也有更好的表现</li>
</ul>
<h3 id="sklearn的roc-auc曲线绘制"><a href="#sklearn的roc-auc曲线绘制" class="headerlink" title="sklearn的roc_auc曲线绘制"></a>sklearn的roc_auc曲线绘制</h3><ul>
<li>Code: <a target="_blank" rel="noopener" href="https://sklearn.org/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score">https://sklearn.org/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score</a></li>
<li>面试：P-R 曲线和ROC-AUC曲线的区别是什么？分别有何作用？<ul>
<li>hint:</li>
</ul>
</li>
<li>功能: 因为模型输出的是概率，对于分类问题如果我们必须要设定一个阈值来判断正负样本，这里的阈值如何设定则直接决定了我们的评价性能的好坏。</li>
<li>阈值的设定需要考虑到我们的任务：查全率则选择较小的阈值/查准率则选择较大的阈值， ROC曲线的纵轴是真正例率TPR，横轴是假正例率 FPR。</li>
</ul>
<p>$$ TPR = \frac{TP}{TP + TN} \ FPR = \frac{FP}{TN+FP}$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> plot_roc_curve ， plot_precision_recall_curve</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve ， auc </span><br><span class="line"></span><br><span class="line">fpr = <span class="built_in">dict</span>()</span><br><span class="line">tpr = <span class="built_in">dict</span>()</span><br><span class="line">roc_auc = <span class="built_in">dict</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_class):</span><br><span class="line">    fpr[i] ， tpr[i] ，_ = roc_curve(y_test[:，i] ， y_score[:，i])</span><br><span class="line">    roc_auc[i] = auc(fpr[i] ，tpr[i])</span><br><span class="line">    <span class="comment"># print(fpr[i] ， tpr[i] ， roc_auc[i])</span></span><br><span class="line"></span><br><span class="line">fpr[<span class="string">&#x27;micro&#x27;</span>] ， tpr[<span class="string">&#x27;micro&#x27;</span>] ，_  = roc_curve(y_test.ravel() ， y_score.ravel())</span><br><span class="line">roc_auc[<span class="string">&#x27;micro&#x27;</span>] = auc(fpr[<span class="string">&#x27;micro&#x27;</span>] ， tpr[<span class="string">&#x27;micro&#x27;</span>])</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">lw = <span class="number">2</span> </span><br><span class="line">plt.plot(fpr[<span class="number">2</span>] ， tpr[<span class="number">2</span>] ，color = <span class="string">&#x27;darkorange&#x27;</span>， lw = lw ，label = <span class="string">&#x27;Roc curve (area = &#123;:.3f&#125;&#x27;</span>.<span class="built_in">format</span>(roc_auc[<span class="number">2</span>]))</span><br><span class="line">plt.plot([<span class="number">0</span>，<span class="number">1</span>] ， [<span class="number">0</span>，<span class="number">1</span>] ，color =<span class="string">&#x27;navy&#x27;</span>， lw = lw ， linestyle = <span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h3 id="Conclusion-1"><a href="#Conclusion-1" class="headerlink" title="Conclusion"></a>Conclusion</h3><ul>
<li>Stacking 对于 blending的改进： 单个模型训练时候使用了交叉验证 (sklearncross_val_score函数的使用)，使用Stacking集成也是需要调参数集成之后效果并不一定比单个效果好但是似乎会缩短时间</li>
<li>如何画出模型的分类的决策边界：mxtend</li>
<li>如何机器学习调参： GridSearchCV 以及 bayes_opt</li>
<li>了解roc-auc和阈值的关系作用，如何画出roc-auc的曲线图 ： 代码细节</li>
</ul>
<h3 id="Tutorial-1"><a href="#Tutorial-1" class="headerlink" title="Tutorial"></a>Tutorial</h3><p><a target="_blank" rel="noopener" href="https://www.kaggle.com/fayzur/lgb-bayesian-parameters-finding-rank-average">LGB + Bayesian parameters finding + Rank average</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/58204236">Kaggle 贝叶斯优化调参应用</a></p>
<p><a target="_blank" rel="noopener" href="https://sklearn.org/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score">sklearn.metrics.roc_auc_score - scikit-learn 0.19.1 documentation</a></p>
<h1 id="集成学习案例一-（幸福感预测）"><a href="#集成学习案例一-（幸福感预测）" class="headerlink" title="集成学习案例一 （幸福感预测）"></a>集成学习案例一 （幸福感预测）</h1><ul>
<li>DATA: <a target="_blank" rel="noopener" href="https://github.com/datawhalechina/team-learning-data-mining/tree/master/EnsembleLearning/CH6-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%A1%88%E4%BE%8B%E5%88%86%E4%BA%AB/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%901">datawhalechina/team-learning-data-mining</a></li>
</ul>
<h3 id="Step1"><a href="#Step1" class="headerlink" title="Step1"></a><strong>Step1</strong></h3><p><code>读入数据，观察数据，去除target列，然后将训练集和预测集进行组合</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">train = pd.read_csv(<span class="string">&quot;train.csv&quot;</span>， parse_dates=[<span class="string">&#x27;survey_time&#x27;</span>]，encoding=<span class="string">&#x27;latin-1&#x27;</span>) </span><br><span class="line">test = pd.read_csv(<span class="string">&quot;test.csv&quot;</span>， parse_dates=[<span class="string">&#x27;survey_time&#x27;</span>]，encoding=<span class="string">&#x27;latin-1&#x27;</span>) <span class="comment">#latin-1向下兼容ASCII</span></span><br><span class="line">train = train[train[<span class="string">&quot;happiness&quot;</span>]!=-<span class="number">8</span>].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">train_data_copy = train.copy() <span class="comment">#删去&quot;happiness&quot; 为-8的行</span></span><br><span class="line">target_col = <span class="string">&quot;happiness&quot;</span> <span class="comment">#目标列</span></span><br><span class="line">target = train_data_copy[target_col]</span><br><span class="line"><span class="keyword">del</span> train_data_copy[target_col] <span class="comment">#去除目标列</span></span><br><span class="line"></span><br><span class="line">data = pd.concat([train_data_copy，test]，axis=<span class="number">0</span>，ignore_index=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h3 id="step2"><a href="#step2" class="headerlink" title="step2"></a><strong>step2</strong></h3><p><code>数据处理 : 异常值处理，缺失值填充，特殊信息处理利用</code></p>
<ul>
<li>处理异常数值(本案例之中为负数-1，-2，-8)，可以利用pd.series.apply(lambda row : func(row) 对每一列进行统计</li>
<li>处理空数值，利用 fillna(num)进行填补(0 ， 平均，众数，对于连续数据还可以移动平均)，直接定义一个函数接口更加的方便。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">isnull_rate</span>(<span class="params">data</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        按照缺失的比例输出每列的缺失比例，并且以数组形式，按照顺序返回columns</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(((data.isnull().<span class="built_in">sum</span>())/data.shape[<span class="number">0</span>]).sort_values(ascending=<span class="literal">False</span>).<span class="built_in">map</span>(<span class="keyword">lambda</span> x:<span class="string">&quot;&#123;:.2%&#125;&quot;</span>.<span class="built_in">format</span>(x)))</span><br><span class="line">    cols = (((data.isnull().<span class="built_in">sum</span>())/data.shape[<span class="number">0</span>]).sort_values(ascending=<span class="literal">False</span>)).index.tolist()</span><br><span class="line">    <span class="keyword">return</span> cols</span><br><span class="line">cols=isnull_rate(data)</span><br><span class="line"></span><br><span class="line">cols = cols[:<span class="number">8</span>]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fillna</span>(<span class="params">data ， cols =[]</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        对于不fillna(0)的列，记得要单独处理</span></span><br><span class="line"><span class="string">        大致可以按照：数值类(收入)，类别类(1，2)，时间类</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> cols:</span><br><span class="line">        data[col] = data[col].fillna(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line">data = fillna(data ，cols)</span><br></pre></td></tr></table></figure>

<ul>
<li>对于时间戳等等数据，使用pd内置处理时间的函数或者是datetime，会比正则和字符串切片更加的方便。</li>
<li>对于年月日的信息，分年龄段和时间段，可以利用pd.cut()进行分层处理</li>
</ul>
<h3 id="Step3"><a href="#Step3" class="headerlink" title="Step3"></a><strong>Step3</strong></h3><p><code>特征增广 ，特征过滤</code></p>
<ul>
<li>在已有的数据和数据的含义之下，根据实际的意义从已有的数据之内挖掘特征(通常十分的累🥱)，这一个过程应该多讨论和分工合作，毕竟是一些重复的劳动活，若是特征无意义就等于浪费时间</li>
<li>对于类别数据，可以利用 sklearn.preprocessing.OneHotEncoder(categories = ‘auto’)，构造oneHot编码，合成第三类的特征，利用 onehot构建的特征优点有：增强算法鲁邦性(例如56个民族，1-56数字对应特征和56维度的one-hot向量相比会复杂的多)</li>
<li>最后对于构建的特征工程构件的训练数据集，根据不同的特征构建多个的数据集(49特征，263特征，oneHot编码得到的特征)</li>
<li>数据保存出来单独将模型放在py文件里面，更加的有条理和复用</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 特征数据整理并且保存成为npy二进制文件</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line">data = [X_train_49， X_test_49， X_train_263， X_test_263，X_train_383， X_test_383，X_train_oh， X_test_oh ]</span><br><span class="line">name = <span class="string">&#x27;X_train_49， X_test_49， X_train_263， X_test_263，X_train_383， X_test_383，X_train_oh， X_test_oh &#x27;</span>.split(<span class="string">&#x27;，&#x27;</span>)</span><br><span class="line">data = <span class="built_in">zip</span>(name ， data)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_numpy</span>(<span class="params">file_path= <span class="string">&#x27;data_npy&#x27;</span>，data=[]</span>):</span></span><br></pre></td></tr></table></figure>
<p>   特征数据整理并且保存成为npy二进制文件<br>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    for file_name  ，dataset in tqdm.tqdm(data，desc=&quot;save datasets&quot;):</span><br><span class="line">        print(file_name)</span><br><span class="line">        dataset = np.asanyarray(dataset)</span><br><span class="line">        np.save(os.path.join(file_path ， str(file_name)+&#x27;.npy&#x27;) ， dataset)</span><br><span class="line"></span><br><span class="line">save_numpy(data = data)</span><br></pre></td></tr></table></figure></p>
<h3 id="Step4"><a href="#Step4" class="headerlink" title="Step4"></a><strong>Step4</strong></h3><p><code>lightgbm， xgboost， randomforest</code></p>
<p><code>🐶🐶[与其将各种模型试一次，不如好好的尝试这三个模型，然后好好的调整参数， 值得注意的是有气势lightgbm和 xgboost都提供了各种的语言的接口， GPU 以及分布式的部署。]</code></p>
<h3 id="lightgbm-模型的参数保存"><a href="#lightgbm-模型的参数保存" class="headerlink" title="lightgbm 模型的参数保存"></a><strong><a target="_blank" rel="noopener" href="https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.Booster.html">lightgbm</a> 模型的参数保存</strong></h3><ul>
<li><a target="_blank" rel="noopener" href="https://lightgbm.readthedocs.io/en/latest/Parameters.html">lightgbm parameters</a>: <a target="_blank" rel="noopener" href="https://lightgbm.readthedocs.io/en/latest/Parameters.html">https://lightgbm.readthedocs.io/en/latest/Parameters.html</a></li>
<li><code>lgb_263.save_model(*filename*， *num_iteration=None*， *start_iteration=0*， *importance_type=&#39;split&#39;)</code></li>
<li>从<code>lightgbm.feature_importtance()</code> 方法之中获取特征的重要性并且可以画出柱状图或者比例图</li>
<li></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">def lgb( ):</span><br><span class="line">    lgb_263_param = &#123;</span><br><span class="line">            &#x27;num_leaves&#x27; : 10 ，</span><br><span class="line">            &#x27;min_data_in_leaf&#x27; : 20 ， # 叶子可能的最小记录数</span><br><span class="line">            &#x27;objective&#x27; : &#x27;regression&#x27;，</span><br><span class="line">            &#x27;max_depth&#x27; : -1 ，</span><br><span class="line">            &#x27;learning_rate&#x27; :0.01，</span><br><span class="line">            &#x27;boosting&#x27; : &#x27;gbdt&#x27;，</span><br><span class="line">            &#x27;feature_fraction&#x27; : 0.18 ， # 在每次迭代之中随机选择18%的参数来建树</span><br><span class="line">            &#x27;bagging_freq&#x27; : 1 ，</span><br><span class="line">            &#x27;bagging_fraction&#x27;:0.55， # 每次迭代时的数据比例</span><br><span class="line">            &#x27;bagging_seed&#x27;:14，</span><br><span class="line">            &#x27;metric&#x27; :&#x27;mse&#x27;，</span><br><span class="line">            &#x27;lambda_l1&#x27; : 0.1 ，</span><br><span class="line">            &#x27;lambda_l2&#x27; : 0.2，</span><br><span class="line">            &#x27;verbosity&#x27; : -1</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    folds = StratifiedKFold(n_splits=5 ， shuffle=True ， random_state=4)</span><br><span class="line">    oof_lgb_263 = np.zeros(len(X_train_263))</span><br><span class="line">    predictions_lgb_263 = np.zeros(len(X_test_263))</span><br><span class="line"></span><br><span class="line">    for fold ，(train_idx ， val_idx) in enumerate(folds.split(X_train_263 ， y_train)):</span><br><span class="line">        print(&quot;=================flod [&#123;&#125;/&#123;&#125;]====================&quot;.format(fold+1 ， 5))</span><br><span class="line"></span><br><span class="line">        train_data = lgb.Dataset(X_train_263[train_idx] ， y_train[train_idx])</span><br><span class="line">        val_data = lgb.Dataset(X_train_263[val_idx] ， y_train[val_idx])</span><br><span class="line"></span><br><span class="line">        num_round = 1000</span><br><span class="line">        lgb_263 = lgb.train(lgb_263_param ， train_data ， num_boost_round=num_round ，</span><br><span class="line">                            valid_sets=[train_data ， val_data] ， verbose_eval=500， early_stopping_rounds=800)</span><br><span class="line"></span><br><span class="line">        oof_lgb_263[val_idx] = lgb_263.predict(X_train_263[val_idx] ， num_iteration=lgb_263.best_iteration)</span><br><span class="line"></span><br><span class="line">        predictions_lgb_263 += lgb_263.predict(X_test_263 ， num_iteration=lgb_263.best_iteration) / folds.n_splits</span><br><span class="line"></span><br><span class="line">    print(&quot;CV socre : &#123;:.8f&#125;&quot;.format(mean_squared_error(oof_lgb_263 ， target)))</span><br><span class="line"></span><br><span class="line">    lgb_263.save_model(filename=&#x27;lbg263.txt&#x27;)</span><br><span class="line">    # print(list(lgb_263.feature_importance()))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong><a target="_blank" rel="noopener" href="https://xgboost.readthedocs.io/en/latest/parameter.html">xgboost</a>  Home’Page</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://xgboost.readthedocs.io/en/latest/parameter.html">xgboost parameter</a> :<a target="_blank" rel="noopener" href="https://xgboost.readthedocs.io/en/latest/parameter.html">https://xgboost.readthedocs.io/en/latest/parameter.html</a></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">xgboost</span>():</span></span><br><span class="line"></span><br><span class="line">    xgb_263_params = &#123;</span><br><span class="line">        <span class="string">&#x27;eta&#x27;</span> :<span class="number">0.02</span> ，</span><br><span class="line">        <span class="string">&#x27;max_depth&#x27;</span> :<span class="number">6</span> ，</span><br><span class="line">        <span class="string">&#x27;min_child_wight&#x27;</span> : <span class="number">3</span> ，</span><br><span class="line">        <span class="string">&#x27;gamma&#x27;</span> :<span class="number">0</span> ，</span><br><span class="line">        <span class="string">&#x27;subsample&#x27;</span> : <span class="number">0.7</span>，</span><br><span class="line">        <span class="string">&#x27;colsample_bytree&#x27;</span> : <span class="number">0.3</span> ，</span><br><span class="line">        <span class="string">&#x27;lambda&#x27;</span>:<span class="number">2</span>，</span><br><span class="line">        <span class="string">&#x27;objective&#x27;</span>:<span class="string">&#x27;reg:linear&#x27;</span>，</span><br><span class="line">        <span class="string">&#x27;eval_metric&#x27;</span> : <span class="string">&#x27;rmse&#x27;</span>，</span><br><span class="line">        <span class="string">&#x27;silent&#x27;</span>: <span class="literal">True</span>，</span><br><span class="line">        <span class="string">&#x27;nthread&#x27;</span>: -<span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    folds = StratifiedKFold(n_splits=<span class="number">5</span> ， shuffle=<span class="literal">True</span> ， random_state=<span class="number">4</span>)</span><br><span class="line">    oof_xgb_263 = np.zeros(<span class="built_in">len</span>(X_train_263))</span><br><span class="line">    predictions_xgb_263 = np.zeros(<span class="built_in">len</span>(X_test_263))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> fold ，(train_idx ， val_idx) <span class="keyword">in</span> <span class="built_in">enumerate</span>(folds.split(X_train_263 ， y_train)):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;=================fold [&#123;&#125;/&#123;&#125;]====================&quot;</span>.<span class="built_in">format</span>(fold+<span class="number">1</span> ， <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">        train_data = xgb.DMatrix(X_train_263[train_idx] ， y_train[train_idx])</span><br><span class="line">        val_data = xgb.DMatrix(X_train_263[val_idx] ， y_train[val_idx])</span><br><span class="line"></span><br><span class="line">        watchlist = [(train_data， <span class="string">&#x27;data&#x27;</span>) ，(val_data ，<span class="string">&#x27;valid_data&#x27;</span>)]</span><br><span class="line"></span><br><span class="line">        num_round = <span class="number">3000</span></span><br><span class="line">        xgb_263 = xgb.train( params=xgb_263_params，dtrain=train_data ， num_boost_round=num_round ，</span><br><span class="line">                            evals=watchlist， verbose_eval=<span class="number">500</span>， early_stopping_rounds=<span class="number">800</span>)</span><br><span class="line"></span><br><span class="line">        oof_xgb_263[val_idx] = xgb_263.predict(xgb.DMatrix(X_train_263[val_idx]) ， ntree_limit = xgb_263.best_ntree_limit)</span><br><span class="line"></span><br><span class="line">        predictions_xgb_263 += xgb_263.predict( xgb.DMatrix(X_test_263) ， ntree_limit=xgb_263.best_ntree_limit) / folds.n_splits</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;CV socre : &#123;:.8f&#125;&quot;</span>.<span class="built_in">format</span>(mean_squared_error(oof_xgb_263 ， target)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="Step5-Ensemble"><a href="#Step5-Ensemble" class="headerlink" title="Step5 Ensemble"></a><strong>Step5 Ensemble</strong></h3><p><code>Stacking ， Blending ， Voting</code></p>
<ul>
<li><code>def func(): ``` 有利于后续的模型的Stacking 有利于在k-fold里面对每折进行验证和预测 ``` oof_gb_263 = np.zeros(len(X_train_263)) predictions_gb_263 = np.zeros(len(X_test_263)) oof_gb_263 = gb_263.predict(val_data) predictions_gb_263 += gb_263.predict(X_test_263) /folds.n_splits   return oof_gb_263 ， predictions_gb_263</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Stacking</span>():</span></span><br><span class="line"></span><br><span class="line">    train_stack = np.vstack([oof_lgb_263 ， oof_xgb_263 ， oof_rf_263]).transpose()</span><br><span class="line">    test_stack = np.vstack([predictions_lgb_263 ， predictions_xgb_263 ， predictions_rf_263]).transpose()</span><br><span class="line"></span><br><span class="line">    folds_stack = RepeatedKFold(n_splits=<span class="number">5</span> ， n_repeats=<span class="number">2</span> ， random_state=<span class="number">5</span>)</span><br><span class="line">    oof_stack = np.zeros(train_stack.shape[<span class="number">0</span>])</span><br><span class="line">    predictions_lr2 = np.zeros(train_stack.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> fold ， (train_idx ， val_idx) <span class="keyword">in</span> <span class="built_in">enumerate</span>(fold.split(train_stack  ， target)):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;======== fold &#123;&#125;=====&quot;</span>.<span class="built_in">format</span>(fold+<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        train_data ， train_y  = train_stack[train_idx] ， target[train_idx]</span><br><span class="line">        val_data ， val_y = train_stack[val_idx] ， target[val_idx]</span><br><span class="line"></span><br><span class="line">        lr2 = LogisticRegression()</span><br><span class="line">        lr2.fit(train_data ， train_y)</span><br><span class="line"></span><br><span class="line">        oof_stack = lr2.predict(val_data)</span><br><span class="line"></span><br><span class="line">        predictions_lr2 += lr2.predict(test_stack) / <span class="number">10</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;CV socre : &#123;:.8f&#125;&quot;</span>.<span class="built_in">format</span>(mean_squared_error(oof_stack， target)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>GridSearchCV</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"> </span><br><span class="line"><span class="comment">#把要调整的参数以及其候选值 列出来；</span></span><br><span class="line">param_grid = &#123;<span class="string">&quot;gamma&quot;</span>:[<span class="number">0.001</span>，<span class="number">0.01</span>，<span class="number">0.1</span>，<span class="number">1</span>，<span class="number">10</span>，<span class="number">100</span>]，</span><br><span class="line">             <span class="string">&quot;C&quot;</span>:[<span class="number">0.001</span>，<span class="number">0.01</span>，<span class="number">0.1</span>，<span class="number">1</span>，<span class="number">10</span>，<span class="number">100</span>]&#125;</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Parameters:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(param_grid))</span><br><span class="line"> </span><br><span class="line">grid_search = GridSearchCV(SVC()，param_grid，cv=<span class="number">5</span>) <span class="comment">#实例化一个GridSearchCV类，cv交叉验证参数</span></span><br><span class="line">X_train，X_test，y_train，y_test = train_test_split(iris.data，iris.target，random_state=<span class="number">10</span>)</span><br><span class="line">grid_search.fit(X_train，y_train) <span class="comment">#训练，找到最优的参数，同时使用最优的参数实例化一个新的SVC estimator。</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test set score:&#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(grid_search.score(X_test，y_test)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Best parameters:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(grid_search.best_params_))</span><br><span class="line"></span><br><span class="line"><span class="comment">#SVM模型有两个非常重要的参数C与gamma。</span></span><br><span class="line"><span class="comment">#C是惩罚系数，即对误差的容忍度（间隔大小，分类准确度）。C越高，说明越不能容忍出现误差，容易过拟合。C越小，容易欠拟合。C过大或过小，泛化能力变差</span></span><br><span class="line"><span class="comment">#gamma是选择RBF函数作为kernel后，该函数自带的一个参数。隐含地决定了数据映射到新的特征空间后的分布，gamma越大，支持向量越少，gamma值越小，支持向量越多。支持向量的个数影响训练与预测的速度。</span></span><br><span class="line"><span class="comment">#两者独立</span></span><br></pre></td></tr></table></figure>
<p>example code</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.kaggle.com/ragnar123/simple-lgbm-groupkfold-cv">Simple LGBM GroupKFold CV</a></li>
</ul>
<p><strong>Bayes_opt</strong></p>
<ul>
<li>一个如何用bayes_opt参数搜索，lightgbm</li>
<li><a target="_blank" rel="noopener" href="https://www.kaggle.com/sz8416/simple-bayesian-optimization-for-lightgbm">Simple Bayesian Optimization for LightGBM</a></li>
</ul>
<h3 id="Reference-1"><a href="#Reference-1" class="headerlink" title="Reference"></a><strong>Reference</strong></h3><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/datawhalechina/team-learning-data-mining/blob/master/EnsembleLearning/CH6-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%A1%88%E4%BE%8B%E5%88%86%E4%BA%AB/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%901/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0-%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%901.ipynb">datawhalechina/team-learning-data-mining</a></li>
<li><a target="_blank" rel="noopener" href="https://xgboost.readthedocs.io/en/latest/parameter.html">XGBoost Parameters - xgboost 1.5.0-SNAPSHOT documentation</a></li>
<li><a target="_blank" rel="noopener" href="https://lightgbm.readthedocs.io/en/latest/Parameters.html">Parameters - LightGBM 3.2.1.99 documentation</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_30868737/article/details/108385115">XGBoost学习（六）：输出特征重要性以及筛选特征_安然烟火的博客-CSDN博客_xgboost 特征重要性</a></li>
<li><a target="_blank" rel="noopener" href="https://mathpretty.com/10649.html">LightGBM使用简单介绍</a></li>
</ul>

  </div>
</article>


    <div class="blog-post-comments">
        <div id="utterances_thread">
            <noscript>Please enable JavaScript to view the comments.</noscript>
        </div>
    </div>


        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/recording/">Recording</a></li>
         
          <li><a href="/links/">Links</a></li>
         
          <li><a href="/about/">About</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Pre-prepation"><span class="toc-number">1.</span> <span class="toc-text">Pre-prepation</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Voting-amp-Bagging"><span class="toc-number">2.</span> <span class="toc-text">Voting &amp; Bagging</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Voting-%E6%8A%95%E7%A5%A8%E6%B3%95"><span class="toc-number">2.0.1.</span> <span class="toc-text">Voting 投票法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Bagging-%E8%87%AA%E5%8A%A9%E9%87%87%E6%A0%B7%E6%B3%95"><span class="toc-number">2.0.2.</span> <span class="toc-text">Bagging 自助采样法</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Boosting"><span class="toc-number">3.</span> <span class="toc-text">Boosting</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Concepts"><span class="toc-number">3.0.1.</span> <span class="toc-text">Concepts</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AdaBoost"><span class="toc-number">3.0.2.</span> <span class="toc-text">AdaBoost</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#XGBoost"><span class="toc-number">3.0.3.</span> <span class="toc-text">XGBoost</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#LightGBM"><span class="toc-number">3.0.4.</span> <span class="toc-text">LightGBM</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conlusion"><span class="toc-number">3.0.5.</span> <span class="toc-text">Conlusion</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Reference"><span class="toc-number">3.0.6.</span> <span class="toc-text">Reference</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Blending"><span class="toc-number">4.</span> <span class="toc-text">Blending</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Concept"><span class="toc-number">4.0.1.</span> <span class="toc-text">Concept</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Algorithms"><span class="toc-number">4.0.2.</span> <span class="toc-text">Algorithms</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Blending-Example"><span class="toc-number">4.0.3.</span> <span class="toc-text">Blending Example</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusion"><span class="toc-number">4.0.4.</span> <span class="toc-text">Conclusion</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Tutorial"><span class="toc-number">4.0.5.</span> <span class="toc-text">Tutorial</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Stacking"><span class="toc-number">5.</span> <span class="toc-text">Stacking</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Concept-1"><span class="toc-number">5.0.1.</span> <span class="toc-text">Concept</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Algorithm"><span class="toc-number">5.0.2.</span> <span class="toc-text">Algorithm</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Stacking-Example"><span class="toc-number">5.0.3.</span> <span class="toc-text">Stacking Example</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#mxtend-%E5%B7%A5%E5%85%B7%E5%8C%85-link"><span class="toc-number">5.0.4.</span> <span class="toc-text">mxtend 工具包 link</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sklearn%E4%B9%8B%E8%B0%83%E5%8F%82%E6%96%B9%E6%B3%95GridSearchCV-%E4%BB%A5%E5%8F%8A-cross-val-score"><span class="toc-number">5.0.5.</span> <span class="toc-text">sklearn之调参方法GridSearchCV 以及 cross_val_score</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sklearn%E4%B9%8B%E8%B0%83%E5%8F%82%E6%96%B9%E6%B3%95-%E8%B4%9D%E5%8F%B6%E6%96%AFbayes-opt"><span class="toc-number">5.0.6.</span> <span class="toc-text">sklearn之调参方法 -贝叶斯bayes_opt</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sklearn%E7%9A%84roc-auc%E6%9B%B2%E7%BA%BF%E7%BB%98%E5%88%B6"><span class="toc-number">5.0.7.</span> <span class="toc-text">sklearn的roc_auc曲线绘制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusion-1"><span class="toc-number">5.0.8.</span> <span class="toc-text">Conclusion</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Tutorial-1"><span class="toc-number">5.0.9.</span> <span class="toc-text">Tutorial</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%A1%88%E4%BE%8B%E4%B8%80-%EF%BC%88%E5%B9%B8%E7%A6%8F%E6%84%9F%E9%A2%84%E6%B5%8B%EF%BC%89"><span class="toc-number">6.</span> <span class="toc-text">集成学习案例一 （幸福感预测）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Step1"><span class="toc-number">6.0.1.</span> <span class="toc-text">Step1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#step2"><span class="toc-number">6.0.2.</span> <span class="toc-text">step2</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Step3"><span class="toc-number">6.0.3.</span> <span class="toc-text">Step3</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Step4"><span class="toc-number">6.0.4.</span> <span class="toc-text">Step4</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#lightgbm-%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%82%E6%95%B0%E4%BF%9D%E5%AD%98"><span class="toc-number">6.0.5.</span> <span class="toc-text">lightgbm 模型的参数保存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Step5-Ensemble"><span class="toc-number">6.0.6.</span> <span class="toc-text">Step5 Ensemble</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Reference-1"><span class="toc-number">6.0.7.</span> <span class="toc-text">Reference</span></a></li></ol></li></ol></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2021/05/10/Notes-EnsembleLearning/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2021/05/10/Notes-EnsembleLearning/&text=Notes-EnsembleLearning"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2021/05/10/Notes-EnsembleLearning/&title=Notes-EnsembleLearning"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2021/05/10/Notes-EnsembleLearning/&is_video=false&description=Notes-EnsembleLearning"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Notes-EnsembleLearning&body=Check out this article: http://example.com/2021/05/10/Notes-EnsembleLearning/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2021/05/10/Notes-EnsembleLearning/&title=Notes-EnsembleLearning"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2021/05/10/Notes-EnsembleLearning/&title=Notes-EnsembleLearning"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2021/05/10/Notes-EnsembleLearning/&title=Notes-EnsembleLearning"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2021/05/10/Notes-EnsembleLearning/&title=Notes-EnsembleLearning"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2021/05/10/Notes-EnsembleLearning/&name=Notes-EnsembleLearning&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2021/05/10/Notes-EnsembleLearning/&t=Notes-EnsembleLearning"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2016-2022
    yangjing
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a href="/recording/">Recording</a></li><!--
     --><!--
       --><li><a href="/links/">Links</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->
 
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script> 




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script> 
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Umami Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

    <script type="text/javascript">
      var utterances_repo = 'yangjingla/comments';
      var utterances_issue_term = 'pathname';
      var utterances_label = 'Comment';
      var utterances_theme = 'github-light';

      (function(){
          var script = document.createElement('script');

          script.src = 'https://utteranc.es/client.js';
          script.setAttribute('repo', utterances_repo);
          script.setAttribute('issue-term', 'pathname');
          script.setAttribute('label', utterances_label);
          script.setAttribute('theme', utterances_theme);
          script.setAttribute('crossorigin', 'anonymous');
          script.async = true;
          (document.getElementById('utterances_thread')).appendChild(script);
      }());
  </script>

</body>
</html>
