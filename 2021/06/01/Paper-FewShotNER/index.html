<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="Few-Shot Named Entity Recognition: A Comprehensive StudyProblemBuilding NER System is labor-intensive, time-consuming task, prohibitively expensive  and requires rich domain Knowledge and expert exper">
<meta property="og:type" content="article">
<meta property="og:title" content="Paper-FewShotNER">
<meta property="og:url" content="http://example.com/2021/06/01/Paper-FewShotNER/index.html">
<meta property="og:site_name" content="Yang Jing">
<meta property="og:description" content="Few-Shot Named Entity Recognition: A Comprehensive StudyProblemBuilding NER System is labor-intensive, time-consuming task, prohibitively expensive  and requires rich domain Knowledge and expert exper">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/008eGmZEgy1gpdqosv4sxj31bd0u07cq.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/008eGmZEgy1gpay36kszmj30oo0n6n1c.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/008eGmZEgy1gpb1z4v60sj30oo0z4agy.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNgy1gr2ssma8kyj31sq0o47a7.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNgy1gr2kheq143j31id0u0drf.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNgy1gr2sgsrmyij31aq0smaib.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNgy1gr2luggcvgj316g0tik0r.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNgy1gr2sd1efnbj316g0gwtby.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNgy1grlcrt5ygxj30ly0rojvx.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNgy1grld6a9dqjj315w0suq8x.jpg">
<meta property="article:published_time" content="2021-06-01T08:49:03.000Z">
<meta property="article:modified_time" content="2022-02-08T11:55:42.140Z">
<meta property="article:author" content="yangjing">
<meta property="article:tag" content="Paper">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://tva1.sinaimg.cn/large/008eGmZEgy1gpdqosv4sxj31bd0u07cq.jpg">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon2.jpeg">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/favicon2.jpeg" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon2.jpeg">
        
      
    
    <!-- title -->
    <title>Paper-FewShotNER</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
      <link rel="alternate" href="/true" title="Yang Jing" type="application/atom+xml" />
    
	<!-- mathjax -->
	
		<script type="text/x-mathjax-config">
		  MathJax.Hub.Config({
			tex2jax: {
			  skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
			  inlineMath: [['$','$']]
			}
		  });
		</script>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
	
<meta name="generator" content="Hexo 6.0.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a href="/recording/">Recording</a></li><!--
     --><!--
       --><li><a href="/links/">Links</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post" href="/2022/02/08/%E8%AE%BF%E9%97%AEGit-%E5%8A%A0%E9%80%9F-%E5%B8%B8%E8%A7%81%E7%9A%84Git%E5%91%BD%E4%BB%A4/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Next post" href="/2021/05/10/Notes-EnsembleLearning/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2021/06/01/Paper-FewShotNER/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2021/06/01/Paper-FewShotNER/&text=Paper-FewShotNER"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2021/06/01/Paper-FewShotNER/&title=Paper-FewShotNER"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2021/06/01/Paper-FewShotNER/&is_video=false&description=Paper-FewShotNER"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Paper-FewShotNER&body=Check out this article: http://example.com/2021/06/01/Paper-FewShotNER/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2021/06/01/Paper-FewShotNER/&title=Paper-FewShotNER"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2021/06/01/Paper-FewShotNER/&title=Paper-FewShotNER"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2021/06/01/Paper-FewShotNER/&title=Paper-FewShotNER"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2021/06/01/Paper-FewShotNER/&title=Paper-FewShotNER"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2021/06/01/Paper-FewShotNER/&name=Paper-FewShotNER&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2021/06/01/Paper-FewShotNER/&t=Paper-FewShotNER"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Few-Shot-Named-Entity-Recognition-A-Comprehensive-Study"><span class="toc-number">1.</span> <span class="toc-text">Few-Shot Named Entity Recognition: A Comprehensive Study</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Problem"><span class="toc-number">1.0.1.</span> <span class="toc-text">Problem</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Motivation"><span class="toc-number">1.0.2.</span> <span class="toc-text">Motivation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Method"><span class="toc-number">1.0.3.</span> <span class="toc-text">Method</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Future-amp-Conclusion"><span class="toc-number">1.0.4.</span> <span class="toc-text">Future&amp;Conclusion</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Distantly-Supervised-Named-Entity-Recognition-using-Positive-Unlabeled-Learning-ACL2019"><span class="toc-number">2.</span> <span class="toc-text">Distantly Supervised Named Entity Recognition using Positive-Unlabeled Learning[ACL2019]</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Problem-1"><span class="toc-number">2.0.1.</span> <span class="toc-text">Problem</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Moitvation"><span class="toc-number">2.0.2.</span> <span class="toc-text">Moitvation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Method-1"><span class="toc-number">2.0.3.</span> <span class="toc-text">Method</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusion-amp-Future"><span class="toc-number">2.0.4.</span> <span class="toc-text">Conclusion &amp; Future</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Improving-Low-Resource-Named-Entity-Recognition-using-Joint-sentence-and-Token-Labeling-ACL2020"><span class="toc-number">3.</span> <span class="toc-text">Improving Low-Resource Named Entity Recognition using Joint sentence and Token Labeling[ACL2020]</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Problem-2"><span class="toc-number">3.0.1.</span> <span class="toc-text">Problem</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Motivation-1"><span class="toc-number">3.0.2.</span> <span class="toc-text">Motivation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Model"><span class="toc-number">3.0.3.</span> <span class="toc-text">Model</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusion-amp-Question"><span class="toc-number">3.0.4.</span> <span class="toc-text">Conclusion &amp; Question</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#TriggerNER-Learning-with-Entity-Triggers-as-Explanations-for-Named-Entity-Recognition-ACL2020"><span class="toc-number">4.</span> <span class="toc-text">TriggerNER: Learning with Entity Triggers as Explanations for Named Entity Recognition[ACL2020]</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Problem-3"><span class="toc-number">4.0.1.</span> <span class="toc-text">Problem</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Motivation-2"><span class="toc-number">4.0.2.</span> <span class="toc-text">Motivation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Model-1"><span class="toc-number">4.0.3.</span> <span class="toc-text">Model</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusion"><span class="toc-number">4.0.4.</span> <span class="toc-text">Conclusion</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#A-Unified-Generative-Framework-for-Various-NER-Subtasks-arxiv"><span class="toc-number">5.</span> <span class="toc-text">A Unified Generative Framework for Various NER Subtasks[arxiv]</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Problem-4"><span class="toc-number">5.0.1.</span> <span class="toc-text">Problem</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Method-BART-PointNet"><span class="toc-number">5.0.2.</span> <span class="toc-text">Method(BART+ PointNet)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusion-1"><span class="toc-number">5.0.3.</span> <span class="toc-text">Conclusion</span></a></li></ol></li></ol></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        Paper-FewShotNER
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">yangjing</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2021-06-01T08:49:03.000Z" itemprop="datePublished">2021-06-01</time>
        
        (Updated: <time datetime="2022-02-08T11:55:42.140Z" itemprop="dateModified">2022-02-08</time>)
        
      
    </div>


      

      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link-link" href="/tags/Paper/" rel="tag">Paper</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <h1 id="Few-Shot-Named-Entity-Recognition-A-Comprehensive-Study"><a href="#Few-Shot-Named-Entity-Recognition-A-Comprehensive-Study" class="headerlink" title="Few-Shot Named Entity Recognition: A Comprehensive Study"></a>Few-Shot Named Entity Recognition: A Comprehensive Study</h1><h3 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h3><p>Building NER System is labor-intensive, time-consuming task, prohibitively expensive  and requires rich domain Knowledge and expert experienceã€‚</p>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p><strong>Tranditonal NER vs Few-shot NER?</strong></p>
<ul>
<li>Tranditional NER are trained in the standard supervised leanring paradigrms, In the real world application, the more favorable scenarios are given for each entity type.which yield task**: few-shot NER.**</li>
<li>Small number of labeled tokens are available, it renders difficulties for supervised fine-tuning approach.</li>
</ul>
<p><strong>Metrics for few-shot NER ?</strong></p>
<p>$$L(x,y) = \sum_{(X,Y) \in D^L} \sum_{i=1}^{T} KL(y_i || q(y_i | x_i))$$</p>
<p>Where KL divergence between two distribution and prediction probability:</p>
<p>$$ KL(p||q) = E_{p}log(p|q) = Softmax(W*f(x) + b )$$</p>
<p><strong>Related Task and Methods</strong></p>
<ul>
<li>Prototype-based methods:</li>
<li>supervised pre-training:</li>
<li>Self-training: teacher-student architecture, Distillation technology in NLP</li>
</ul>
<h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><p>Three orthogonal directions (also complementary) show in Figure:</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gpdqosv4sxj31bd0u07cq.jpg" alt="https://tva1.sinaimg.cn/large/008eGmZEgy1gpdqosv4sxj31bd0u07cq.jpg"></p>
<p><strong>Prototype-based method</strong></p>
<ul>
<li><p>How to adapt meta- learning such as prototype-based methods (prototype network) for few- shot NER?</p>
</li>
<li><p>Core idea is use episodic classification paradigm to simulate few-shor settings during model training.</p>
</li>
</ul>
<p><strong>Noisy supervised pre-training</strong></p>
<ul>
<li><p>How to leverage freely-available web data as noisy supervised pre-training data?</p>
</li>
<li><p>motivated by mask-pretraining-modelâ€™s performance, but PLMs treats each token equally which is not aligned with the goal of NER.and the intuition inspires us to endow the backbone network an ability to outweight the representations of entity for NER.</p>
</li>
</ul>
<p><strong>Self-Training</strong></p>
<ul>
<li><p>How to leverage unlabeled in-domain sentences in a semi-supervised manner?</p>
</li>
<li><p>Train two model : teacher model <em>Î¸</em> and student model  $\theta$</p>
</li>
</ul>
<p><strong>Utilize a nearest enighbor classifier based on the contextualized representation</strong></p>
<p>Training Free NER</p>
<ul>
<li>Neighbor-tagging:</li>
<li>Examplebased NER:</li>
</ul>
<h3 id="Future-amp-Conclusion"><a href="#Future-amp-Conclusion" class="headerlink" title="Future&amp;Conclusion"></a>Future&amp;Conclusion</h3><ul>
<li>Prototype-based methods, Noisy Supervised Pretraining, Self-Training</li>
<li>â“How to combine Span-based and BIO-based ?</li>
<li>â“public code and benchmarks for few-shot learning ?</li>
</ul>
<h1 id="Distantly-Supervised-Named-Entity-Recognition-using-Positive-Unlabeled-Learning-ACL2019"><a href="#Distantly-Supervised-Named-Entity-Recognition-using-Positive-Unlabeled-Learning-ACL2019" class="headerlink" title="Distantly Supervised Named Entity Recognition using Positive-Unlabeled Learning[ACL2019]"></a>Distantly Supervised Named Entity Recognition using Positive-Unlabeled Learning[ACL2019]</h1><h3 id="Problem-1"><a href="#Problem-1" class="headerlink" title="Problem"></a>Problem</h3><ul>
<li>ä¼ ç»Ÿçš„åŸºäºåºåˆ—æ ‡æ³¨æ–¹æ³•çš„å‘½åå®ä½“è¯†åˆ«ï¼Œæ˜¯å…¸å‹çš„ç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œè¿‡åº¦çš„ä¾èµ–äºæ•°æ®å’Œæ•°æ®å’Œè´¨é‡ï¼Œç„¶è€Œå¯¹äºä¸€äº›ç‰¹æ®Šè¡Œä¸šï¼ˆä¾‹å¦‚ï¼šç”Ÿç‰©/åŒ»å­¦)é¢†åŸŸæ— æ³•è·å¾—å¤§è§„æ¨¡çš„é«˜è´¨é‡æ•°æ®çš„åœºæ™¯ä¹‹ä¸‹ï¼Œç°æœ‰çš„ä¸€äº›æ¨¡å‹ä¸èƒ½å¤Ÿè¡¨ç°å¾ˆå¥½çš„çš„æ€§èƒ½ã€‚</li>
<li>æ„é€ ä¸€ä¸ªèƒ½å¤Ÿè¦†ç›–æ‰€æœ‰çš„å®ä½“çš„å­—å…¸æ˜¯ä¸å¯èƒ½çš„ï¼Œå¦‚ä½•åˆ©ç”¨æ–‡æœ¬ä¹‹ä¸­åŒ¹é…åˆ°çš„å®ä½“å’ŒæœªåŒ¹é…åˆ°çš„å®ä½“å‘¢ï¼Ÿ</li>
</ul>
<h3 id="Moitvation"><a href="#Moitvation" class="headerlink" title="Moitvation"></a>Moitvation</h3><ul>
<li>Positive-unlabeled(PU) learning problem:<ul>
<li>perform the NER task using only unlabeled data and named entity dictionaries.</li>
<li>Postive data(å­—å…¸åŒ¹é…åˆ°çš„å®ä½“) å’Œ Unlabeled data( æœªåŒ¹é…åˆ°çš„å®ä½“)</li>
<li>å¦‚æœæˆ‘ä»¬åªç”¨å­—å…¸å’Œæ²¡æœ‰æ ‡æ³¨çš„æ•°æ®ï¼Œèƒ½å¦åŒæ ·è¿›è¡Œå‘½åä½“è¯†åˆ«å‘¢ï¼Ÿ</li>
</ul>
</li>
</ul>
<h3 id="Method-1"><a href="#Method-1" class="headerlink" title="Method"></a>Method</h3><ul>
<li><p>Unbiased Positive-Unlabeled learning</p>
<ul>
<li> when there are only a set of positive (P) examples and a set of unlabeled (U) examples, which contains both positive and negative examples.</li>
</ul>
<p>$$R_l = n E_{x,y=0} l(f(x_i), 0) + p E_{x,y=1} l(f(x),1)$$</p>
<ul>
<li>å…¶ä¸­è®° <em>Ï€</em>â€„=â€„<em>p</em>(<em>y</em>â€„=â€„1) ä¸ºæ­£æ ·æœ¬ ï¼Œå…¶å®æœ¬å¼çš„å…³é”®åœ¨äºå¦‚ä½•ä¼°è®¡ç¬¬ä¸€é¡¹unlabled data  </li>
</ul>
<p>$$R_l = n E_{x,y=0}l(f(x_i), 0) = E_{x} l(f(x),0) - p E_{x,y=1} l(f(x), 0)$$ ã€‚</p>
</li>
</ul>
<ul>
<li><p>å…¶ä¸­ $n_u$ å’Œ  åˆ†åˆ«æ˜¯æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬çš„æ€»æ•°</p>
<p>$$ \hat{R}<em>l = \frac{1}{n_u} \sum</em>{i=1}^{n_u} l(f(x), 0) + \frac{\pi_p}{n_p} \sum_{i=1}^{n_p}( l(f(x_i^{p},1) - l(f(x_i^p), 0)) $$</p>
</li>
<li><p>Consistent Positive-Unlabeled Learning</p>
<ul>
<li>ä»€ä¹ˆæ˜¯ä¸€è‡´æ€§ï¼Ÿæœ‰ä»€ä¹ˆä½œç”¨ï¼Ÿ[èƒ½å¤Ÿä¸€å®šç¨‹åº¦ä¸Šç¼“è§£è¿‡æ‹Ÿåˆé—®é¢˜å—ï¼Ÿ]</li>
<li>æ–‡ç« åœ¨2.3èŠ‚å’Œé™„å½•ä¹‹ä¸­ä»‹ç»è¯æ˜äº†ä¸€ä¸ªç»“è®ºï¼šåªè¦åœ¨ä¸Šå¼ä¹‹ä¸­çš„losså‡½æ•°æ˜¯ä¸€ä¸ªå­˜åœ¨ä¸Šç•Œçš„å‡½æ•°ï¼Œé‚£ä¹ˆ$\hat{R_l}$å°±æ˜¯ä¸€è‡´çš„consistent.</li>
</ul>
</li>
<li><p>ä½¿ç”¨negative/positive ä¸¤ä¸ªæ ‡ç­¾è¿›è¡Œæ ‡æ³¨ï¼Œè€Œä¸æ˜¯ä¼ ç»Ÿçš„BIO/BIOESè¿›è¡Œæ ‡æ³¨ ï¼Œåˆ©ç”¨å­—å…¸å’Œæœ€å¤§å‰å‘åŒ¹é…ç­–ç•¥è¿›è¡ŒåŒ¹é…</p>
</li>
<li><p>Label Assignment, Data Labeling using the Dictionary, PU Learning Classifier,Loss definiton,Label Inference and Adapted PU Learning.</p>
<ul>
<li>Lebel Inference: ä¸ºæ¯ä¸€ä¸ªå®ä½“çš„ç±»å‹å»ºç«‹äº†å¤šä¸ªåˆ†ç±»å™¨ï¼Œå› æ­¤ä¼šå­˜åœ¨ä¸€ä¸ªå®ä½“è¢«å¤šä¸ªåˆ†ç±»å™¨åŒæ—¶é¢„æµ‹ä¸ºæ­£ç±»ï¼Œæ­¤æ—¶æˆ‘ä»¬åªéœ€è¦é€‰æ‹©æ¦‚ç‡$f(w|s)$æœ€é«˜çš„åˆ™å¯.</li>
<li>AdaSamplingï¼šå› ä¸ºæ­£æ ·æœ¬è¦æ»¡è¶³$p(X|Y=1)ç‹¬ç«‹åŒåˆ†å¸ƒ ï¼Œè¿™ä¸ªæ¡ä»¶é€šå¸¸æ— æ³•æ»¡è¶³ï¼Œ å…³é”®æ˜¯å’Œèƒ½å¤Ÿæ¸æ¸çš„æ¥ä¸°å¯Œæˆ‘ä»¬è¯å…¸çš„å†…å®¹(å…¶å®å°±æ˜¯ä¼ªæ ‡ç­¾çš„æ€æƒ³ï¼Œä½†æ˜¯å¦‚ä½•è·å¾—å¯é çœŸå®çš„ä¼ªæ ‡ç­¾å‘¢ï¼Ÿ)</li>
</ul>
</li>
</ul>
<h3 id="Conclusion-amp-Future"><a href="#Conclusion-amp-Future" class="headerlink" title="Conclusion &amp; Future"></a>Conclusion &amp; Future</h3><ul>
<li>ç»“åˆè¯å…¸çš„ä¸€ç§æ˜æ˜å®ä½“è¯†åˆ«PU Learning å­¦ä¹ ç®—æ³•ï¼Œèƒ½å¤Ÿç¼“è§£æ²¡æœ‰è¶³å¤Ÿçš„æ ‡æ³¨æ•°æ®çš„é—®é¢˜ï¼Œç”šè‡³zero-shot ï¼Ÿ</li>
<li>èƒ½å¤Ÿè¯æ˜çš„PU learning å­¦ä¹ ç®—æ³•åº”è¯¥æ˜¯ä¸€è‡´çš„å’Œæ— åè§ï¼ˆconsitent and unbiasedï¼‰, æœ‰åŠ©äºå‡å°‘æˆ‘ä»¬çš„å­—å…¸çš„è§„æ¨¡ã€‚</li>
<li>èƒ½å¦å¼•å…¥ä¸€äº›æ›´åŠ å¤§çš„è¯å…¸çš„åŒæ—¶ï¼Œæé«˜æŸ¥è¯¢çš„é€Ÿåº¦ï¼Ÿæ¯”å¦‚å¼•å…¥wikiç™¾ç§‘ç­‰ç­‰è§„æ¨¡ååˆ†å¤§çš„çŸ¥è¯†åº“ï¼Ÿ</li>
</ul>
<h1 id="Improving-Low-Resource-Named-Entity-Recognition-using-Joint-sentence-and-Token-Labeling-ACL2020"><a href="#Improving-Low-Resource-Named-Entity-Recognition-using-Joint-sentence-and-Token-Labeling-ACL2020" class="headerlink" title="Improving Low-Resource Named Entity Recognition using Joint sentence and Token Labeling[ACL2020]"></a>Improving Low-Resource Named Entity Recognition using Joint sentence and Token Labeling[ACL2020]</h1><blockquote>
<p>We present a joint model that supports multi-class classification and introduce a simple variant of self-attention that allows the model to learn scaling factors. Our model produces 3.78%, 4.20%, 2.08% improvements in F1 over the BiLSTM-CRF baseline on ecommerce product titles in three different low-resource languages: Vietnamese, Thai, and Indonesian, respectively</p>
</blockquote>
<h3 id="Problem-2"><a href="#Problem-2" class="headerlink" title="Problem"></a>Problem</h3><ul>
<li>Sentences-level labels is one of plausible methods to impove low-resource NER</li>
<li>Sentences-level labels vs token-level ?[Sentences-level label is easy to get and token-level is costly to annotate]</li>
</ul>
<h3 id="Motivation-1"><a href="#Motivation-1" class="headerlink" title="Motivation"></a>Motivation</h3><ul>
<li>for low resource NER -&gt;to get sufficient large number of labeled data<ul>
<li>multi-task learning, pre-training</li>
<li>Coarse grained NER, fine-tuning bilingual word embedding, intergrating POS tagging,</li>
</ul>
</li>
<li>previous study have exploited token-level information from auxiliary tasks,few of them have tried to use sentence-level information</li>
<li>jointly labeling framework</li>
</ul>
<h3 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h3><p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gpay36kszmj30oo0n6n1c.jpg" alt="https://tva1.sinaimg.cn/large/008eGmZEgy1gpay36kszmj30oo0n6n1c.jpg"></p>
<ul>
<li><p>Two tasks</p>
<ul>
<li>Task-specific layers include a <strong>CRF for NER</strong> and a linear layer for <strong>sentence classification</strong></li>
<li>the diffierence between multi tasks learning is the goal which is to imporve the performance of the main task NER</li>
<li>Joint labeling objective: $ L_{joint} = L_{NER} + L_{C}$</li>
</ul>
</li>
<li><p><strong>soft-attention mechanism</strong></p>
<ul>
<li>H*â€²â€„=â€„<em>H</em>â€…+â€…<em>H</em>â€…âŠ—â€…<em>a</em></li>
</ul>
<p>â€‹    $$atten(Q,K,V) = softmax(\frac{QK^{T}}{\sigma})V \ \sigma = min(relu(w_4 H^{T} +b_4), \sqrt {d_n/n}) +1 $$                </p>
</li>
<li><p>Datasets</p>
</li>
</ul>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gpb1z4v60sj30oo0z4agy.jpg" alt="https://tva1.sinaimg.cn/large/008eGmZEgy1gpb1z4v60sj30oo0z4agy.jpg"></p>
<h3 id="Conclusion-amp-Question"><a href="#Conclusion-amp-Question" class="headerlink" title="Conclusion &amp; Question"></a>Conclusion &amp; Question</h3><ul>
<li>joint sentence and token labeling model is remarkably effective for low-resource NER</li>
<li>when the sentence and token label is weakly related, model can support multi-class classifications ?</li>
<li>multi-task learning and jointly label learning ?soft-attention vs hard attention ?</li>
<li>åœ¨å®ä½“å’Œå…³ç³»çš„è”åˆæŠ½å–çš„å®éªŒä¹‹ä¸­ï¼Œå¦‚æœæˆ‘çš„é‡ç‚¹æ˜¯ä»…ä»…æ˜¯å…³ç³»æˆ–è€…å®ä½“ï¼Œæˆ‘ä¸éœ€è¦å…¼é¡¾æˆ‘éœ€è¦æ€ä¹ˆå»åšï¼Ÿ</li>
<li>å¦‚ä½•åœ¨å…³ç³»ï¼Œå®ä½“ï¼ŒæŒ‡ä»£ç­‰ç­‰å¤šä»»åŠ¡çš„åœºæ™¯ä¹‹ä¸‹æ¥åŠ å…¥ä¸€äº›è¯¸å¦‚åˆ†ç±»ä»»åŠ¡ï¼Ÿ</li>
<li>é’ˆå¯¹ç§‘æŠ€æ–‡çŒ®çš„ä¿¡æ¯çš„æŠ½å–ï¼Œæ˜¯å¦åªéœ€è¦æ ¹æ®å­¦ç§‘çš„ç±»åˆ«[clueä¸Šæœ‰ç›¸å…³çš„æ•°æ®é›†]æ¥å½“ä½œsentence labeling? [æœ¬æ–‡çš„å®ä½“çš„æ¥æºå…¨éƒ¨éƒ½æ˜¯åœ¨æ ‡é¢˜ä¹‹ä¸­è¿›è¡Œæ ‡æ³¨çš„å—ï¼Ÿ]</li>
</ul>
<h1 id="TriggerNER-Learning-with-Entity-Triggers-as-Explanations-for-Named-Entity-Recognition-ACL2020"><a href="#TriggerNER-Learning-with-Entity-Triggers-as-Explanations-for-Named-Entity-Recognition-ACL2020" class="headerlink" title="TriggerNER: Learning with Entity Triggers as Explanations for Named Entity Recognition[ACL2020]"></a>TriggerNER: Learning with Entity Triggers as Explanations for Named Entity Recognition[ACL2020]</h1><blockquote>
<p>In this paper, we introduce â€œentity triggers,â€ an effec- tive proxy of human explanations for facili- tating label-efficient learning of NER models. An entity trigger is defined as a group ofwords in a sentence that helps to explain why humans would recognize an entity in the sentence. </p>
</blockquote>
<h3 id="Problem-3"><a href="#Problem-3" class="headerlink" title="Problem"></a>Problem</h3><ul>
<li>ä½èµ„æºåœºæ™¯ä¸‹çš„å®ä½“æŠ½å–ï¼Œå¦‚ä½•è¿›è¡ŒåŠç›‘ç£å­¦ä¹ -&gt;è‡ªç›‘ç£å­¦ä¹ -&gt;æ— ç›‘ç£å­¦ä¹ çš„ä»»åŠ¡ï¼Ÿ</li>
<li>**How to cost-effectively learn a model for NER using entity triggers ? **</li>
</ul>
<h3 id="Motivation-2"><a href="#Motivation-2" class="headerlink" title="Motivation"></a>Motivation</h3><p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gr2ssma8kyj31sq0o47a7.jpg" alt="Screen Shot 2021-06-01 at 10.25.23 AM"></p>
<ul>
<li>åœ¨å¥å­ä¹‹ä¸­æœ‰äº›æ˜¯å¸¦æœ‰ä¸€äº›å¸¸è¯†æ€§çš„çŸ¥è¯†ï¼Œæ¯”å¦‚ ã€å›½é˜²ç§‘å¤§ä½äºå››æ–¹åªã€‘è¿™ä¸ªå¥å­ä¸­ï¼Œæˆ‘ä»¬æ ¹æ®ã€ä½äºã€‘èƒ½å¤Ÿæ¨æ–­åé¢çš„å®ä½“ã€å››æ–¹åªã€‘æ˜¯åœ°åLocation.æ‰€ä»¥ã€ä½äºã€‘å°±æ˜¯æˆ‘ä»¬æ‰€æåˆ°çš„ ã€Entity triggersã€‘ã€‚</li>
<li>è¿˜æ˜¯åœ¨æ¨¡å‹å¼•å…¥æ›´å¤šçš„å…ˆéªŒçŸ¥è¯†ï¼Œä¸ºæ¨¡å‹å¼•å…¥è§„åˆ™åŒ¹é…çš„ä¿¡æ¯ï¼Œç±»ä¼¼äºè¯­å¥æ¨¡ç‰ˆã€‚</li>
<li>We propose a novel framework named Trigger Matching Net- work that learns trigger representations indicative of entity types during the training phase, and iden- tifies triggers in an unlabeled sentence at infer- ence time to guide a traditional entity tagger for delivering better overall NER performance.</li>
<li>Our intuition is that triggers acting as cues for the same named-entity type should have similar trigger representations, and thus triggers can be identified in an unlabeled sentence at inference time by soft-matching between the sentence representation and trigger representations seen during training. We perform such soft- matching between the sentence representation and trigger representa- tions seen during training. We perform such soft- matching using a self-attention mechanism.</li>
</ul>
<h3 id="Model-1"><a href="#Model-1" class="headerlink" title="Model"></a>Model</h3><p>ã€€<strong>Training Stage</strong></p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gr2kheq143j31id0u0drf.jpg" alt="Screen Shot 2021-06-01 at 10.38.32 AM"></p>
<p><strong>Trigger Encoding &amp; Semantic Matching</strong></p>
<ul>
<li><p> Jointly train the trigger encoder <strong>(TrigEncoder)</strong> and the attention-based trigger matching module (<strong>TrigMatcher)</strong> using a shared embedding space.</p>
</li>
<li><p>Learning to match triggers and sentences based on attention-based representations, we use <strong>contrastive loss</strong>.</p>
<p>â€‹    $$ L_{SM} = 1_{matched} \frac{1}{2} ||g_s - g_t||^2 + (1- 1_{matched} \frac{1}{2}(max(0, m-d)))$$</p>
</li>
</ul>
<p><strong>Inference</strong></p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gr2sgsrmyij31aq0smaib.jpg" alt="Screen Shot 2021-06-01 at 3.17.34 PM"></p>
<p><strong>Inference on Unlabeled Sentences</strong></p>
<ul>
<li>Â TrigMatcher + Trigger dictionary!</li>
<li>å¯¹äºå·²ç»è®­ç»ƒå¥½çš„trigger vectoræ„å»ºä¸€ä¸ªå­—å…¸ï¼Œåœ¨æœªæ ‡æ³¨çš„è¯­æ–™ä¸Šé¢åˆ©ç”¨TrigMatcher è¿›è¡ŒåŒ¹é…ï¼Œæœ€åé€šè¿‡ä¸€ä¸ªContrasive Loss è¿›è¡Œå­¦ä¹ ã€‚</li>
</ul>
<p><strong>Experiments</strong></p>
<p>éªŒè¯å°‘æ ·æœ¬çš„æ•°æ®å®éªŒè®¾è®¡ï¼š</p>
<ul>
<li>ä»…ä½¿ç”¨20%çš„æ•°æ®åˆ™å¯ä»¥è¾¾åˆ°80%çš„æ•ˆæœï¼ˆ20%çš„æ•°æ®æ˜¯å¦ç»è¿‡ç²¾æŒ‘ç»†é€‰è¿˜æ˜¯éšæœºé€‰æ‹©å‘¢ï¼Ÿï¼‰</li>
</ul>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gr2luggcvgj316g0tik0r.jpg" alt="Screen Shot 2021-06-01 at 11.28.30 AM"></p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gr2sd1efnbj316g0gwtby.jpg" alt="Screen Shot 2021-06-01 at 3.13.55 PM"></p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><ul>
<li> æœ¬æ–‡ã€Related Workã€‘å¯¹äºå°‘æ ·æœ¬/ä½èµ„æºä¸‹çš„NER åšäº†ä¸€äº›æ¢³ç†å¤§æ¦‚åŒ…æ‹¬ä¸‰ä¸ªæ–¹é¢ï¼š1.lattice 2.distantly supervision  3.active learning 4. linking rules</li>
<li>èƒ½ä¸èƒ½å¤Ÿæ ¹æ®è¿™ç¯‡TriggerNERçš„æ€æƒ³+MRC  ä¹‹ä¸­è‡ªåŠ¨çš„æ„å»ºé«˜è´¨é‡çš„ Queryæ¥æé«˜æ¨¡å‹çš„æ€§èƒ½ï¼Ÿâ€“&gt; åœ¨ä¼ ç»Ÿå’Œå…¸å‹çš„MRCä»»åŠ¡æˆ–è€…æ˜¯æ•°æ®é›†é‡Œé¢çš„ queryæ˜¯å¦‚ä½•äº§ç”Ÿçš„å‘¢ï¼Ÿ</li>
<li>æœ¬æ–‡ä¹‹ä¸­çš„trigger æ˜¯åœ¨[conll2003,bc5cdr]ä¸¤ä¸ªæ•°æ®é›†äººä¸ºçš„æ ‡æ³¨å‡ºæ¥ï¼Œç±»ä¼¼äºä¸ä¹Ÿæ˜¯å°†å­—å…¸æ›´æ¢æˆäº†ä¸€ä¸ªtriggerï¼Œå¦‚ä½•åœ¨äº‹ä»¶æŠ½å–ä¹‹ä¸­ä¸€æ ·çš„è§¦å‘è¯è‡ªåŠ¨å‘ç°( å¼€æ”¾åŸŸäº‹ä»¶/ä¿¡æ¯æŠ½å–)ï¼Ÿ</li>
<li>ç”±äºè®ºæ–‡å†™ä½œè¯­è¨€çš„ç‹¬ç‰¹æ€§ï¼Œç§‘æŠ€æ–‡çŒ®ä¹‹ä¸­æ‰€è°“çš„ triggeræ˜¯ä¸æ˜¯æ›´åŠ çš„ç®€å•å‘¢ï¼Ÿèƒ½ä¸èƒ½å½“ä½œä½èµ„æºåœºæ™¯ä¸‹çš„ç§‘æŠ€æ–‡çŒ®çš„ä¿¡æ¯æŠ½å–ï¼Ÿ</li>
<li>ğŸ…ã€active learning ã€‘for data annotation ï¼Ÿ</li>
</ul>
<h1 id="A-Unified-Generative-Framework-for-Various-NER-Subtasks-arxiv"><a href="#A-Unified-Generative-Framework-for-Various-NER-Subtasks-arxiv" class="headerlink" title="A Unified Generative Framework for Various NER Subtasks[arxiv]"></a>A Unified Generative Framework for Various NER Subtasks[arxiv]</h1><blockquote>
<p>To that end, we propose to formulate the NER subtasks as an entity span sequence genera- tion task, which can be solved by a unified sequence-to-sequence (Seq2Seq) framework. Based on our unified framework, we can leverage the pre-trained Seq2Seq model to solve all three kinds of NER subtasks without the special design of the tagging schema or ways to enumerate spans</p>
</blockquote>
<h3 id="Problem-4"><a href="#Problem-4" class="headerlink" title="Problem"></a>Problem</h3><ul>
<li>NER has been a fundamental task of Natural Language Processing, and three kinds of NER subtasks have been recongnized in previous work.</li>
</ul>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1grlcrt5ygxj30ly0rojvx.jpg" alt="Screen Shot 2021-06-17 at 4.40.11 PM"></p>
<h3 id="Method-BART-PointNet"><a href="#Method-BART-PointNet" class="headerlink" title="Method(BART+ PointNet)"></a>Method(BART+ PointNet)</h3><p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1grld6a9dqjj315w0suq8x.jpg" alt="Screen Shot 2021-06-17 at 4.54.10 PM"></p>
<p>Seq2Seqçš„ç”Ÿæˆæ¨¡å‹</p>
<ul>
<li><p>å…¸å‹çš„ç”Ÿæˆä»»åŠ¡ï¼š</p>
</li>
<li><p>ç”Ÿæˆèƒ½åŠ›æ¯”è¾ƒå¼ºçš„æ¨¡å‹(é€‚åˆäºé˜…è¯»ç†è§£ç­‰ç­‰ç”Ÿæˆä»»åŠ¡)ï¼šBART ï¼Œ  T5, Longformer</p>
</li>
</ul>
<p> BART</p>
<ul>
<li>BART uses the encoder to input the corrupted sentence and the decoder to recover the original sentence.</li>
</ul>
<p>NER Datasets</p>
<ul>
<li>Flat NER : CONLL03, OntoNotes </li>
<li>Nested NER : ACE04,ACE05 (å€Ÿé‰´å¤„ç†çš„dygieè„šæœ¬) ï¼Œ Genia</li>
</ul>
<h3 id="Conclusion-1"><a href="#Conclusion-1" class="headerlink" title="Conclusion"></a>Conclusion</h3><ul>
<li>å‘½åå®ä½“é—®é¢˜å¯ä»¥åˆ†ä¸ºï¼šFlat NER, Nested NER, Discontinous NER</li>
<li>æœ¬ç¯‡æ–‡ç« å¯¹äºNERÂ çš„ä¸¤ç§å­˜åœ¨çš„å…¸å‹çš„é—®é¢˜å’Œä¸¤ç§ä¸»æµçš„æ–¹æ³•éƒ½æœ‰å¾ˆè¯¦ç»†çš„ä¼˜ç¼ºç‚¹çš„æ¯”è¾ƒ<ul>
<li>Sequence tagging: æ²¡æœ‰ä¸€ç§å¥½çš„æ ‡æ³¨æ–¹å¼èƒ½å¤ŸåŒæ—¶è§£å†³ä¸Šé¢çš„ä¸‰ä¸ªé—®é¢˜</li>
<li>Span-based: é€šè¿‡æšä¸¾æ‰€æœ‰çš„å®ä½“(å¯¹äºéè¿ç»­å®ä½“å¤æ‚åº¦é«˜)ä¹Ÿä¸èƒ½å¤ŸåŒæ—¶è§£å†³ä¸Šè¿°çš„é—®é¢˜ï¼ŒåŸºäºSpançš„æ–¹æ³•åœ¨ç»“æ„åŒ–æ¨ç†å’Œè§£ç çš„æ—¶å€™éƒ½ä¼šååˆ†çš„å¤æ‚ï¼›Span-based å—åˆ°spançš„é•¿åº¦çš„å‚æ•°çš„è®¾ç½®</li>
</ul>
</li>
</ul>

  </div>
</article>


    <div class="blog-post-comments">
        <div id="utterances_thread">
            <noscript>Please enable JavaScript to view the comments.</noscript>
        </div>
    </div>


        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/recording/">Recording</a></li>
         
          <li><a href="/links/">Links</a></li>
         
          <li><a href="/about/">About</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Few-Shot-Named-Entity-Recognition-A-Comprehensive-Study"><span class="toc-number">1.</span> <span class="toc-text">Few-Shot Named Entity Recognition: A Comprehensive Study</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Problem"><span class="toc-number">1.0.1.</span> <span class="toc-text">Problem</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Motivation"><span class="toc-number">1.0.2.</span> <span class="toc-text">Motivation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Method"><span class="toc-number">1.0.3.</span> <span class="toc-text">Method</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Future-amp-Conclusion"><span class="toc-number">1.0.4.</span> <span class="toc-text">Future&amp;Conclusion</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Distantly-Supervised-Named-Entity-Recognition-using-Positive-Unlabeled-Learning-ACL2019"><span class="toc-number">2.</span> <span class="toc-text">Distantly Supervised Named Entity Recognition using Positive-Unlabeled Learning[ACL2019]</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Problem-1"><span class="toc-number">2.0.1.</span> <span class="toc-text">Problem</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Moitvation"><span class="toc-number">2.0.2.</span> <span class="toc-text">Moitvation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Method-1"><span class="toc-number">2.0.3.</span> <span class="toc-text">Method</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusion-amp-Future"><span class="toc-number">2.0.4.</span> <span class="toc-text">Conclusion &amp; Future</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Improving-Low-Resource-Named-Entity-Recognition-using-Joint-sentence-and-Token-Labeling-ACL2020"><span class="toc-number">3.</span> <span class="toc-text">Improving Low-Resource Named Entity Recognition using Joint sentence and Token Labeling[ACL2020]</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Problem-2"><span class="toc-number">3.0.1.</span> <span class="toc-text">Problem</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Motivation-1"><span class="toc-number">3.0.2.</span> <span class="toc-text">Motivation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Model"><span class="toc-number">3.0.3.</span> <span class="toc-text">Model</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusion-amp-Question"><span class="toc-number">3.0.4.</span> <span class="toc-text">Conclusion &amp; Question</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#TriggerNER-Learning-with-Entity-Triggers-as-Explanations-for-Named-Entity-Recognition-ACL2020"><span class="toc-number">4.</span> <span class="toc-text">TriggerNER: Learning with Entity Triggers as Explanations for Named Entity Recognition[ACL2020]</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Problem-3"><span class="toc-number">4.0.1.</span> <span class="toc-text">Problem</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Motivation-2"><span class="toc-number">4.0.2.</span> <span class="toc-text">Motivation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Model-1"><span class="toc-number">4.0.3.</span> <span class="toc-text">Model</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusion"><span class="toc-number">4.0.4.</span> <span class="toc-text">Conclusion</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#A-Unified-Generative-Framework-for-Various-NER-Subtasks-arxiv"><span class="toc-number">5.</span> <span class="toc-text">A Unified Generative Framework for Various NER Subtasks[arxiv]</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Problem-4"><span class="toc-number">5.0.1.</span> <span class="toc-text">Problem</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Method-BART-PointNet"><span class="toc-number">5.0.2.</span> <span class="toc-text">Method(BART+ PointNet)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusion-1"><span class="toc-number">5.0.3.</span> <span class="toc-text">Conclusion</span></a></li></ol></li></ol></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2021/06/01/Paper-FewShotNER/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2021/06/01/Paper-FewShotNER/&text=Paper-FewShotNER"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2021/06/01/Paper-FewShotNER/&title=Paper-FewShotNER"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2021/06/01/Paper-FewShotNER/&is_video=false&description=Paper-FewShotNER"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Paper-FewShotNER&body=Check out this article: http://example.com/2021/06/01/Paper-FewShotNER/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2021/06/01/Paper-FewShotNER/&title=Paper-FewShotNER"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2021/06/01/Paper-FewShotNER/&title=Paper-FewShotNER"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2021/06/01/Paper-FewShotNER/&title=Paper-FewShotNER"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2021/06/01/Paper-FewShotNER/&title=Paper-FewShotNER"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2021/06/01/Paper-FewShotNER/&name=Paper-FewShotNER&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2021/06/01/Paper-FewShotNER/&t=Paper-FewShotNER"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2016-2022
    yangjing
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a href="/recording/">Recording</a></li><!--
     --><!--
       --><li><a href="/links/">Links</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->
 
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script> 




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script> 
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Umami Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

    <script type="text/javascript">
      var utterances_repo = 'yangjingla/comments';
      var utterances_issue_term = 'pathname';
      var utterances_label = 'Comment';
      var utterances_theme = 'github-light';

      (function(){
          var script = document.createElement('script');

          script.src = 'https://utteranc.es/client.js';
          script.setAttribute('repo', utterances_repo);
          script.setAttribute('issue-term', 'pathname');
          script.setAttribute('label', utterances_label);
          script.setAttribute('theme', utterances_theme);
          script.setAttribute('crossorigin', 'anonymous');
          script.async = true;
          (document.getElementById('utterances_thread')).appendChild(script);
      }());
  </script>

</body>
</html>
