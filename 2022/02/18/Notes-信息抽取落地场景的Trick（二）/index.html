<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="本文主要汇总分享以下，在信息抽取比赛之中的一些常见trick以及代码实现。在工业届-信息抽取比赛Trick (二)之中会总结分享一些在工业界做信息抽取的一些tricks。  命名实体识别的几点心得   刷爆3路榜单，信息抽取冠军方案分享：嵌套NER+关系抽取+实体标准化   标注样本少怎么办？「文本增强+半监督学习」总结（从PseudoLabel到UDA&#x2F;FixMatch）   如何解决NLP分类">
<meta property="og:type" content="article">
<meta property="og:title" content="Notes-信息抽取落地场景Trick(一)">
<meta property="og:url" content="http://example.com/2022/02/18/Notes-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%90%BD%E5%9C%B0%E5%9C%BA%E6%99%AF%E7%9A%84Trick%EF%BC%88%E4%BA%8C%EF%BC%89/index.html">
<meta property="og:site_name" content="Yang Jing">
<meta property="og:description" content="本文主要汇总分享以下，在信息抽取比赛之中的一些常见trick以及代码实现。在工业届-信息抽取比赛Trick (二)之中会总结分享一些在工业界做信息抽取的一些tricks。  命名实体识别的几点心得   刷爆3路榜单，信息抽取冠军方案分享：嵌套NER+关系抽取+实体标准化   标注样本少怎么办？「文本增强+半监督学习」总结（从PseudoLabel到UDA&#x2F;FixMatch）   如何解决NLP分类">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://s4.ax1x.com/2022/02/24/bFq5J1.png">
<meta property="og:image" content="https://s4.ax1x.com/2022/02/24/bFqfo9.png">
<meta property="og:image" content="https://s4.ax1x.com/2022/02/24/bFq4iR.png">
<meta property="og:image" content="https://s4.ax1x.com/2022/02/24/bFqWdJ.png">
<meta property="article:published_time" content="2022-02-18T12:53:28.000Z">
<meta property="article:modified_time" content="2022-02-24T13:13:44.311Z">
<meta property="article:author" content="yangjing">
<meta property="article:tag" content="Notes">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s4.ax1x.com/2022/02/24/bFq5J1.png">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.jpg">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/favicon.jpg" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.jpg">
        
      
    
    <!-- title -->
    <title>Notes-信息抽取落地场景Trick(一)</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
      <link rel="alternate" href="/true" title="Yang Jing" type="application/atom+xml" />
    
	<!-- mathjax -->
	
		<script type="text/x-mathjax-config">
		  MathJax.Hub.Config({
			tex2jax: {
			  skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
			  inlineMath: [['$','$']]
			}
		  });
		</script>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
	
<meta name="generator" content="Hexo 6.0.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a href="/recording/">Recording</a></li><!--
     --><!--
       --><li><a href="/links/">Links</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post" href="/2022/03/06/Talks-%E7%A7%91%E7%A0%94%E4%B8%8E%E7%94%9F%E6%B4%BB/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Next post" href="/2022/02/11/Paper-%E8%BD%AC-%E5%BD%93%E6%88%91%E4%BB%AC%E8%B0%88%E7%A7%91%E5%AD%A6%E7%A0%94%E7%A9%B6%E7%9A%84%E5%88%9B%E6%96%B0%E6%80%A7-Novelty-%E6%97%B6%EF%BC%8C%E6%88%91%E4%BB%AC%E5%9C%A8%E8%B0%88%E4%BA%9B%E4%BB%80%E4%B9%88/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2022/02/18/Notes-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%90%BD%E5%9C%B0%E5%9C%BA%E6%99%AF%E7%9A%84Trick%EF%BC%88%E4%BA%8C%EF%BC%89/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2022/02/18/Notes-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%90%BD%E5%9C%B0%E5%9C%BA%E6%99%AF%E7%9A%84Trick%EF%BC%88%E4%BA%8C%EF%BC%89/&text=Notes-信息抽取落地场景Trick(一)"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2022/02/18/Notes-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%90%BD%E5%9C%B0%E5%9C%BA%E6%99%AF%E7%9A%84Trick%EF%BC%88%E4%BA%8C%EF%BC%89/&title=Notes-信息抽取落地场景Trick(一)"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2022/02/18/Notes-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%90%BD%E5%9C%B0%E5%9C%BA%E6%99%AF%E7%9A%84Trick%EF%BC%88%E4%BA%8C%EF%BC%89/&is_video=false&description=Notes-信息抽取落地场景Trick(一)"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Notes-信息抽取落地场景Trick(一)&body=Check out this article: http://example.com/2022/02/18/Notes-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%90%BD%E5%9C%B0%E5%9C%BA%E6%99%AF%E7%9A%84Trick%EF%BC%88%E4%BA%8C%EF%BC%89/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2022/02/18/Notes-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%90%BD%E5%9C%B0%E5%9C%BA%E6%99%AF%E7%9A%84Trick%EF%BC%88%E4%BA%8C%EF%BC%89/&title=Notes-信息抽取落地场景Trick(一)"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2022/02/18/Notes-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%90%BD%E5%9C%B0%E5%9C%BA%E6%99%AF%E7%9A%84Trick%EF%BC%88%E4%BA%8C%EF%BC%89/&title=Notes-信息抽取落地场景Trick(一)"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2022/02/18/Notes-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%90%BD%E5%9C%B0%E5%9C%BA%E6%99%AF%E7%9A%84Trick%EF%BC%88%E4%BA%8C%EF%BC%89/&title=Notes-信息抽取落地场景Trick(一)"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2022/02/18/Notes-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%90%BD%E5%9C%B0%E5%9C%BA%E6%99%AF%E7%9A%84Trick%EF%BC%88%E4%BA%8C%EF%BC%89/&title=Notes-信息抽取落地场景Trick(一)"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2022/02/18/Notes-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%90%BD%E5%9C%B0%E5%9C%BA%E6%99%AF%E7%9A%84Trick%EF%BC%88%E4%BA%8C%EF%BC%89/&name=Notes-信息抽取落地场景Trick(一)&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2022/02/18/Notes-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%90%BD%E5%9C%B0%E5%9C%BA%E6%99%AF%E7%9A%84Trick%EF%BC%88%E4%BA%8C%EF%BC%89/&t=Notes-信息抽取落地场景Trick(一)"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0%E7%AC%94%E8%AE%B0"><span class="toc-number">1.</span> <span class="toc-text">美团技术文章笔记</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%9A%E5%8A%A1%E5%9C%BA%E6%99%AF"><span class="toc-number">1.1.</span> <span class="toc-text">业务场景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B"><span class="toc-number">1.2.</span> <span class="toc-text">技术选型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%8D%E5%85%B8%E6%9E%84%E5%BB%BA"><span class="toc-number">1.3.</span> <span class="toc-text">词典构建</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%95%88%E7%8E%87"><span class="toc-number">1.4.</span> <span class="toc-text">模型效率</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%8E%B7%E5%8F%96"><span class="toc-number">1.5.</span> <span class="toc-text">数据获取</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93%E5%92%8C%E5%B1%95%E6%9C%9B"><span class="toc-number">1.6.</span> <span class="toc-text">总结和展望</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%B3%E4%BA%8E%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%ABTrick-%E7%9A%84%E6%80%BB%E7%BB%93"><span class="toc-number">2.</span> <span class="toc-text">关于实体识别Trick 的总结</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-1%EF%BC%9A%E9%A2%86%E5%9F%9F%E8%AF%8D%E5%85%B8%E5%8C%B9%E9%85%8D"><span class="toc-number">2.1.</span> <span class="toc-text">trick 1：领域词典匹配</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-2%EF%BC%9A%E8%A7%84%E5%88%99%E6%8A%BD%E5%8F%96"><span class="toc-number">2.2.</span> <span class="toc-text">trick 2：规则抽取</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-3%EF%BC%9A%E8%AF%8D%E5%90%91%E9%87%8F%E9%80%89%E5%8F%96%EF%BC%9A%E8%AF%8D%E5%90%91%E9%87%8F-or-%E5%AD%97%E5%90%91%E9%87%8F%EF%BC%9F"><span class="toc-number">2.3.</span> <span class="toc-text">trick 3：词向量选取：词向量 or 字向量？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-4%EF%BC%9A%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E5%99%A8-%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%EF%BC%9F"><span class="toc-number">2.4.</span> <span class="toc-text">trick 4：特征提取器 如何选择？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-5%EF%BC%9A%E4%B8%93%E6%9C%89%E5%90%8D%E7%A7%B0%E6%80%8E%E4%B9%88%E5%A4%84%E7%90%86%EF%BC%9F"><span class="toc-number">2.5.</span> <span class="toc-text">trick 5：专有名称怎么处理？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-6%EF%BC%9A%E6%A0%87%E6%B3%A8%E6%95%B0%E6%8D%AE%E4%B8%8D%E8%B6%B3%E6%80%8E%E4%B9%88%E5%A4%84%E7%90%86%EF%BC%9F"><span class="toc-number">2.6.</span> <span class="toc-text">trick 6：标注数据不足怎么处理？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-7%EF%BC%9A%E5%B5%8C%E5%A5%97%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%80%8E%E4%B9%88%E5%A4%84%E7%90%86-%E3%80%90%E6%B3%A8%EF%BC%9A%E5%8F%82%E8%80%83-%E8%B5%84%E6%96%993%E3%80%91"><span class="toc-number">2.7.</span> <span class="toc-text">trick 7：嵌套命名实体识别怎么处理 【注：参考 资料3】</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-8%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E8%AF%B4-%E3%80%8C%E8%AF%8D%E6%B1%87%E5%A2%9E%E5%BC%BA%E3%80%8D-%E6%96%B9%E6%B3%95%E5%AF%B9%E4%BA%8E%E4%B8%AD%E6%96%87-NER-%E4%BB%BB%E5%8A%A1%E6%9C%89%E6%95%88%EF%BC%9F"><span class="toc-number">2.8.</span> <span class="toc-text">trick 8：为什么说 「词汇增强」 方法对于中文 NER 任务有效？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-9%EF%BC%9ANER%E5%AE%9E%E4%BD%93span%E8%BF%87%E9%95%BF%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F"><span class="toc-number">2.9.</span> <span class="toc-text">trick 9：NER实体span过长怎么办？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-10-NER-%E6%A0%87%E6%B3%A8%E6%95%B0%E6%8D%AE%E5%99%AA%E5%A3%B0%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">2.10.</span> <span class="toc-text">trick 10: NER 标注数据噪声问题？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-11%EF%BC%9A%E7%BB%99%E5%AE%9A%E4%B8%A4%E4%B8%AA%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E4%BB%BB%E5%8A%A1%EF%BC%8C%E4%B8%80%E4%B8%AA%E4%BB%BB%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%87%8F%E8%B6%B3%E5%A4%9F%EF%BC%8C%E5%8F%A6%E5%A4%96%E4%B8%80%E4%B8%AA%E6%95%B0%E6%8D%AE%E9%87%8F%E5%BE%88%E5%B0%91%EF%BC%8C%E5%8F%AF%E4%BB%A5%E6%80%8E%E4%B9%88%E5%81%9A%EF%BC%9F"><span class="toc-number">2.11.</span> <span class="toc-text">trick 11：给定两个命名实体识别任务，一个任务数据量足够，另外一个数据量很少，可以怎么做？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-12%EF%BC%9ANER-%E6%A0%87%E6%B3%A8%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%9D%87%E8%A1%A1%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">2.12.</span> <span class="toc-text">trick 12：NER 标注数据不均衡问题？</span></a></li></ol></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        Notes-信息抽取落地场景Trick(一)
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">yangjing</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2022-02-18T12:53:28.000Z" itemprop="datePublished">2022-02-18</time>
        
        (Updated: <time datetime="2022-02-24T13:13:44.311Z" itemprop="dateModified">2022-02-24</time>)
        
      
    </div>


      

      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link-link" href="/tags/Notes/" rel="tag">Notes</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <p>本文主要汇总分享以下，在信息抽取比赛之中的一些常见trick以及代码实现。在工业届-信息抽取比赛Trick (二)之中会总结分享一些在工业界做信息抽取的一些tricks。</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/163607351">命名实体识别的几点心得</a></p>
</li>
<li><p> <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/326302618">刷爆3路榜单，信息抽取冠军方案分享：嵌套NER+关系抽取+实体标准化</a></p>
</li>
<li><p> <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/146777068">标注样本少怎么办？「文本增强+半监督学习」总结（从PseudoLabel到UDA/FixMatch）</a></p>
</li>
<li><p> <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/183852900">如何解决NLP分类任务的11个关键问题：类别不平衡&amp;低耗时计算&amp;小样本&amp;鲁棒性&amp;测试检验&amp;长文本分类</a></p>
</li>
<li><p> <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/152463745">工业界如何解决NER问题？12个trick，与你分享～</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1669214?from=article.detail.1843772">美团搜索中NER技术的探索与实践</a></p>
</li>
</ul>
<h1 id="美团技术文章笔记"><a href="#美团技术文章笔记" class="headerlink" title="美团技术文章笔记"></a>美团技术文章笔记</h1><h2 id="业务场景"><a href="#业务场景" class="headerlink" title="业务场景"></a>业务场景</h2><p>到了业界明确自己的任务场景，是最重要的，类似于拿到新的数据集之后第一件事情是观察数据集的分布和统计。美团生活部门的业务场景，美团搜索的NER任务具有以下难点。1） <strong>新增实体数量庞大且增速较快。 2） 口语化的同时领域相关性强。3）性能，性能，性能要求高。</strong></p>
<h2 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h2><ul>
<li>词典 （90%）+ 模型预测（10%）。业务场景之下字典匹配能够达到90%的匹配率，剩下的10%的为了处理未登录词语和其他的场景。词典的优点：灵活，速度快，十分容易进行维护。词典的缺点：无法处理未登录词语，无法处理歧义词语。</li>
</ul>
<p><img src="https://s4.ax1x.com/2022/02/24/bFq5J1.png" alt="Untitled"></p>
<h2 id="词典构建"><a href="#词典构建" class="headerlink" title="词典构建"></a>词典构建</h2><ul>
<li>如何挖掘新词，构建领域词典【以目标为导向，融合多种多样的技术】？如何选取序列文本【频次较高的】？</li>
</ul>
<p>我们的离线实体挖掘是多源多方法的，涉及到的数据源包括结构化的商家信息库、百科词条，半结构化的搜索日志，以及非结构化的用户评论（UGC）等。使用的挖掘方法也包含多种，包括规则、传统机器学习模型、深度学习模型等。</p>
<p>四个维度的统计特征来衡量候选短语可用性：频率，紧密度，信息度，完整信。</p>
<p><img src="https://s4.ax1x.com/2022/02/24/bFqfo9.png" alt="Untitled"></p>
<h2 id="模型效率"><a href="#模型效率" class="headerlink" title="模型效率"></a>模型效率</h2><ul>
<li>如何平衡搜索的效率问题？【使用IDCNN 来替代LSTM/BERT】【BERT进行压缩，剪枝，蒸馏，量化等等技术】【注意关注一些开源的加速框架的调研】</li>
</ul>
<p>我们使用IDCNN-CRF来近似BERT实体识别模型，IDCNN（Iterated Dilated CNN）是一种多层CNN网络，其中低层卷积使用普通卷积操作，通过滑动窗口圈定的位置进行加权求和得到卷积结果，此时滑动窗口圈定的各个位置的距离间隔等于1。高层卷积使用膨胀卷积（Atrous Convolution）操作，滑动窗口圈定的各个位置的距离间隔等于d（d&gt;1）。通过在高层使用膨胀卷积可以减少卷积计算量，同时在序列依赖计算上也不会有损失。在文本挖掘中，IDCNN常用于对LSTM进行替换。实验结果表明，相较于原始BERT模型，在没有明显精度损失的前提下，蒸馏模型的在线预测速度有数十倍的提升。</p>
<p><img src="https://s4.ax1x.com/2022/02/24/bFq4iR.png" alt="两阶段NER(Bert 进行分词， 后序IDCNN进行特征抽取)"></p>
<p>(两阶段NER(Bert 进行分词， 后序IDCNN进行特征抽取)</p>
<h2 id="数据获取"><a href="#数据获取" class="headerlink" title="数据获取"></a>数据获取</h2><ul>
<li>如何在真是业务场景之下获得足够多的数据？【数据标注：远监督， 主动学习】【文本增强】【伪标签数据使用 + 含噪声学习】</li>
</ul>
<p><img src="https://s4.ax1x.com/2022/02/24/bFqWdJ.png" alt="Untitled"></p>
<p><strong>弱监督标注样本生成</strong>.充分利用已有沉淀好的百万级别的词典，对于得到的新的样本进行降噪/标签纠正。实体词典中实体精度较高，理论上来讲模型预测的结果给出的实体类型至少有一个应该是实体词典中给出的该实体类型，否则说明模型对于这类输入的识别效果并不好，需要针对性地补充样本，我们对这类输入的模型结果进行校正后得到标注文本。</p>
<p><strong>弱监督训练</strong>。弱监督模型训练方法包括两种：一是将生成的弱监督样本和标注样本进行混合不区分重新进行模型训练；二是在标注样本训练生成的ModelA基础上，用弱监督样本进行Fine-tuning训练。这两种方式我们都进行了尝试。从实验结果来看，Fine-tuning效果更好。</p>
<h2 id="总结和展望"><a href="#总结和展望" class="headerlink" title="总结和展望"></a><strong>总结和展望</strong></h2><p>本文介绍了美团技术团队在O2O搜索场景下NER任务的特点及技术选型，详述了在实体词典匹配和模型构建方面的探索与实践。</p>
<p><strong>词典匹配</strong>。实体词典匹配针对线上头腰部流量，离线对POI结构化信息、商户评论数据、搜索日志等独有数据进行挖掘，借助<strong>多源数据的挖掘技术，</strong>可以很好的解决领域实体识别问题。在这一部分我们介绍了一种适用于<strong>垂直领域的新词自动挖掘方法</strong>。</p>
<p><strong>模型构建</strong>。我们围绕搜索中NER模型的构建的三个核心问题（性能要求高、领域强相关、标注数据缺乏）进行了探索。针对性能要求高采用了模型蒸馏，预测加速的方法， 使得NER 线上主模型顺利升级为效果更好的BERT。在解决领域相关问题上，分别提出了融合搜索日志、实体词典领域知识的方法，实验结果表明这两种方法可一定程度提升预测准确率。</p>
<p><strong>标注数据获取</strong>。针对标注数据难获取问题，我们提出了一种弱监督方案，一定程度缓解了标注数据少模型预测效果差的问题。</p>
<p><strong>未来的问题</strong>。解决NER未登录识别、歧义多义、领域相关问题上继续深入研究。</p>
<h1 id="关于实体识别Trick-的总结"><a href="#关于实体识别Trick-的总结" class="headerlink" title="关于实体识别Trick 的总结"></a>关于实体识别Trick 的总结</h1><h2 id="trick-1：领域词典匹配"><a href="#trick-1：领域词典匹配" class="headerlink" title="trick 1：领域词典匹配"></a><strong>trick 1：领域词典匹配</strong></h2><ul>
<li>场景：对于某些 常见短语，可以 采用 词典匹配 的方式。</li>
<li>方法：构建一个 常见短语 的 词典，比如 药物、疾病等，然后采用 flashtext 进行 关键词匹配；</li>
<li>优点：<ul>
<li>能够准确的挖掘出 常见短语；</li>
<li>效率更快</li>
</ul>
</li>
<li>缺点：<ul>
<li>对于有些嵌套实体，如果 长实体未包含在词典中，那么将匹配到短实体；</li>
<li>词典收集工作量大</li>
</ul>
</li>
<li>要求会写 【基于字典的前向/后向最大匹配】算法</li>
</ul>
<h2 id="trick-2：规则抽取"><a href="#trick-2：规则抽取" class="headerlink" title="trick 2：规则抽取"></a><strong>trick 2：规则抽取</strong></h2><ul>
<li>场景：对于一些 规定句式，可以 采用 规则匹配 的方式。</li>
<li>方法：构建一些 规则模板库，比如 “ 去|到|抵达|经过 ”、“ 能够|可以 治疗 ” 等；</li>
<li>优点：<ul>
<li>对于某些固定句式，这种方法匹配度高；效率快；</li>
</ul>
</li>
<li>缺点：<ul>
<li>会出现干扰词，eg: “ 去|到|抵达|经过|访 ” 抽取 “特朗普和第一夫人访华” -&gt; (特朗普和第一夫人,)、(华，);</li>
<li>需要手工制定规则；</li>
</ul>
</li>
</ul>
<h2 id="trick-3：词向量选取：词向量-or-字向量？"><a href="#trick-3：词向量选取：词向量-or-字向量？" class="headerlink" title="trick 3：词向量选取：词向量 or 字向量？"></a><strong>trick 3：词向量选取：词向量 or 字向量？</strong></h2><ul>
<li>词向量<ul>
<li>方式：首先对句子进行分词，然后训练 所有词语 的 向量表示，最后利用 这些 词向量 训练模型；</li>
<li>优点：<ul>
<li>能够 帮助 模型 学习 句子中 词汇关系；</li>
</ul>
</li>
<li>缺点：<ul>
<li>OOV 问题；</li>
<li>维护成本高；</li>
<li>如果分词效果不好，那么词向量的质量 将受影响；</li>
</ul>
</li>
</ul>
</li>
<li>字向量<ul>
<li>方式：首先对句子按字切分，然后训练 所有字的 向量表示，最后利用 这些 字向量 训练模型；</li>
<li>优点：<ul>
<li>解决了 词向量的 OOV 问题；</li>
<li>减少人工维护成本；</li>
<li>不用分词；</li>
<li>在训练数据质量较差的时候（比如口语化较多，错别字较多，简称缩写较多等），采用字向量的效果好于词向量;</li>
</ul>
</li>
<li>缺点：<ul>
<li>学不出 词语间 的 关系；</li>
</ul>
</li>
<li>解决方法：<ul>
<li>利用 具有 双向 的 特征提取器 能够 缓解 该功能，eg: bilstm、bert 等；</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="trick-4：特征提取器-如何选择？"><a href="#trick-4：特征提取器-如何选择？" class="headerlink" title="trick 4：特征提取器 如何选择？"></a><strong>trick 4：特征提取器 如何选择？</strong></h2><ul>
<li>短句子：<ul>
<li>模型：LSTM、BiLSTM、CNN、IDCNN</li>
<li>优点：<ul>
<li>在句子较短的情况下， 模型能够 捕获 句子中词语间的依赖关系</li>
</ul>
</li>
</ul>
</li>
<li>长句子：<ul>
<li>模型：Bert</li>
<li>优点：<ul>
<li>在句子较长的情况下， 由于 LSTM、BiLSTM、CNN、IDCNN 会出现 长距离依赖问题，所以性能下降；</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="trick-5：专有名称怎么处理？"><a href="#trick-5：专有名称怎么处理？" class="headerlink" title="trick 5：专有名称怎么处理？"></a><strong>trick 5：专有名称怎么处理？</strong></h2><ul>
<li>场景：#1机组1A锅炉磨煤机故障，#2机组2C炉磨煤机故障。 实体是磨煤机。</li>
<li>方法：在训练ner模型时，可以将一类专业名词改写成一个符号表示</li>
<li>具体操作：<ul>
<li>#1机组、#2机组、#3机组…是一类机组名词，可用符号表示；</li>
<li>1A锅炉，1A炉，1B炉，1C锅炉…是一类锅炉专业名词，可用符号表示；</li>
</ul>
</li>
<li>转化后：<ul>
<li>磨煤机故障，标注：[OOBIIOO]</li>
</ul>
</li>
</ul>
<h2 id="trick-6：标注数据不足怎么处理？"><a href="#trick-6：标注数据不足怎么处理？" class="headerlink" title="trick 6：标注数据不足怎么处理？"></a><strong>trick 6：标注数据不足怎么处理？</strong></h2><ul>
<li>问题介绍：随着模型的愈发精细复杂，需要训练的参数日益庞大，但其训练所需的人工标注数据却因为标注成本的问题难以得到相应地增长。</li>
<li>方法一：远程监督标注数据<ul>
<li>思路：使用远程监督的方法来得到大量的远程监督标注数据</li>
<li>问题：有限覆盖问题（Limited Coverage）。由于用于远程监督的知识库规模有限，大量的实体存在于文本中而未出现在知识库中，导致在远程监督时，将这些未出现在知识库中的实体标注为非实体，从而产生大量的假负例；</li>
</ul>
</li>
<li>方法二：优化模型<ul>
<li>思路：限制参数量，从而使得模型能够在较小的标注数据集上也能够完成训练；</li>
</ul>
</li>
<li>方法三：采用主动学习方法<ul>
<li>思路：<ul>
<li>step 1：先标注一小部分数据，利用这部分标注数据训练模型；</li>
<li>step 2：利用模型去标注 未标记数据；</li>
<li>step 3: 利用 查询函数 筛选 信息量最大的数据；（方法：信息熵计算不确定样本法、多模型投票选取争议性最高样本法）；</li>
<li>step 4：由人工进行标注，并加入到 标注数据中，回到 step 1，直到 样本足够大，或者 模型预测值 趋于平衡；</li>
</ul>
</li>
<li>优点：<ul>
<li>减少标注成本。由于 选取的数据 所包含的信息量较高，所以减少数据 标注成本（本人之前做过一个小实验，发现采用主动学习方法筛选出的总样本的30%左右，训练出的命名实体识别模型性能与全量训练效果相近）；</li>
<li>数据质量高；</li>
</ul>
</li>
<li>缺点：<ul>
<li>如果 查询函数 选取 不对，可能吃力不讨好，也就是 选取的样本存在偏差，比如选到了 离群点。</li>
</ul>
</li>
</ul>
</li>
<li>方法四：迁移学习 【这种方法也蛮常见，问题就是风险太高】</li>
<li>方法五：预训练+自训练 【Self-training Improves Pre-training for Natural Language Understanding】<ul>
<li>背景知识：<ul>
<li>方法：<ul>
<li>预训练（Pre-training）从广义上来讲，是指先在较大规模的数据上对模型训练一波，然后再在具体的下游任务数据中微调。大多数情况下，预训练的含义都比较狭窄：在大规模无标注语料上，用自监督的方式训练模型。这里的自监督方法一般指的是语言模型；</li>
<li>自训练是说有一个Teacher模型Ft和一个Student模型Fs，首先在标注数据上训练Ft，然后用它对大规模无标注数据进行标注，把得到的结果当做伪标注数据去训练Fs。</li>
</ul>
</li>
<li>相同点：用到了大规模无标注的数据</li>
<li>区别：<ul>
<li>预训练始终对针对一个模型进行操作，而自训练却用到了两个模型；</li>
<li>预训练是直接从无标注数据中学习，而自训练是间接地从数据中学习；</li>
</ul>
</li>
</ul>
</li>
<li>思路：<ol>
<li>将一个预训练模型（本文使用RoBERTa_Large）在标注数据上训练，作为教师模型Ft；</li>
<li>使用Ft从海量通用语料中提取相关领域的数据，一般是 抽取出 置信度较高的样本；</li>
<li>用Ft对提取的数据作标注；</li>
<li>用伪标注语料训练学生模型Fs。</li>
</ol>
</li>
</ul>
</li>
<li>方法六：实体词典+BERT相结合<ul>
<li>利用实体词典+BERT相结合，进行半监督自训练**【注：参考 资料11】 **</li>
</ul>
</li>
</ul>
<h2 id="trick-7：嵌套命名实体识别怎么处理-【注：参考-资料3】"><a href="#trick-7：嵌套命名实体识别怎么处理-【注：参考-资料3】" class="headerlink" title="trick 7：嵌套命名实体识别怎么处理 【注：参考 资料3】"></a><strong>trick 7：嵌套命名实体识别怎么处理 【注：参考 资料3】</strong></h2><p>实体嵌套是指在一句文本中出现的实体，存在某个较短实体完全包含在另外一个较长实体内部的情况，如“南京市长”中地名“南京”就嵌套在职务名“南京市长”中。</p>
<p><strong>传统命名实体识别任务的区别。</strong>传统的命名实体识别任务关注的都是平坦实体（Flat entities），即文本中的实体之间不交叉、不嵌套。</p>
<p><strong>序列标注</strong></p>
<ul>
<li>多标签分类<ul>
<li>思路：命名实体识别本来属于基于字的多分类问题，嵌套实体需要将其转化为 多标签问题（即每个字有多种标签，如下图所示）</li>
<li>问题：<ul>
<li>学习难度较大</li>
<li>容易导致label之间依赖关系的缺失</li>
</ul>
</li>
</ul>
</li>
<li>合并标签层<ul>
<li>思路：采用CRF，但设置多个标签层，对于每一个token给出其所有的label，然后将所有标签层合并</li>
<li>问题：<ul>
<li>指数级增加了标签；</li>
<li>对于多层嵌套，稀疏问题较为棘手；</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>指针标注</strong></p>
<ul>
<li>层叠式指针标注<ul>
<li>思路：设置 C 个指针网络</li>
</ul>
</li>
<li>MRC-QA+指针标注<ul>
<li>思路：构建query问题指代所要抽取的实体类型，同时也引入了先验语义知识，如下图（d）所示。在文献中就对不同实体类型构建query，并采取指针标注，此外也构建了 **1 矩阵来判断span是否构成一个实体mention。</li>
</ul>
</li>
</ul>
<p><strong>多头标注</strong></p>
<ul>
<li>构建 span 矩阵<ul>
<li>思路：构建一个 ** 的Span矩阵</li>
<li>说明：如图，Span{呼}{枢}=1，代表「呼吸中枢」是一个部位实体；Span{呼}{累}=2，代表「呼吸中枢受累」是一个症状实体；</li>
<li>问题：<ul>
<li>如何构造Span矩阵问题</li>
<li>如何解决0-1标签稀疏问题</li>
</ul>
</li>
</ul>
</li>
<li>嵌套实体的2篇SOTA之作：<ul>
<li>ACL20的《Named Entity Recognition as Dependency Parsing》采取Biaffine机制构造Span矩阵 <strong>【注：具体可以参考 资料12】</strong>；</li>
<li>EMNLP20的HIT <strong>【注：具体可以参考 资料13】</strong>则通过Biaffine机制专门捕获边界信息，并采取传统的序列标注任务强化嵌套结构的内部信息交互，同时采取focal loss来解决0-1标签不平衡问题。</li>
</ul>
</li>
</ul>
<p> <strong>方片段排列</strong></p>
<ul>
<li>十分直接，如下图（f）所示。对于含T个token的文本，理论上共有 = (+1)/2 种片段排列。如果文本过长，会产生大量的负样本，在实际中需要限制span长度并合理削减负样本。</li>
</ul>
<h2 id="trick-8：为什么说-「词汇增强」-方法对于中文-NER-任务有效？"><a href="#trick-8：为什么说-「词汇增强」-方法对于中文-NER-任务有效？" class="headerlink" title="trick 8：为什么说 「词汇增强」 方法对于中文 NER 任务有效？"></a><strong>trick 8：为什么说 「词汇增强」 方法对于中文 NER 任务有效？</strong></h2><ul>
<li>动机：虽然<strong>基于字符的NER系统通常好于基于词汇（经过分词）的方法</strong>，但<strong>基于字符的NER没有利用词汇信息</strong>，而<strong>词汇边界对于实体边界通常起着至关重要的作用</strong>。</li>
<li>目标：<strong>如何在基于字符的NER系统中引入词汇信息</strong></li>
<li>思路：<ul>
<li>方法一：设计一个动态框架，能够兼容词汇输入 <strong>【注：具体可以参考 资料6-10】</strong></li>
<li>方法二：采用多种分词工具和多种句法短语⼯具进行融合来提取候选实体，并结合词典进行NER</li>
</ul>
</li>
</ul>
<h2 id="trick-9：NER实体span过长怎么办？"><a href="#trick-9：NER实体span过长怎么办？" class="headerlink" title="trick 9：NER实体span过长怎么办？"></a><strong>trick 9：NER实体span过长怎么办？</strong></h2><ul>
<li>动机：如果NER任务中某一类实体span比较长（⽐如医疗NER中的⼿术名称是很长的），直接采取CRF解码可能会导致很多连续的实体span断裂；</li>
<li>解决方法：<ul>
<li>加入规则进行修正</li>
<li>引入指针网络+CRF构建多任务学习。指针网络会更容易捕捉较长的span，不过指针网络的收敛是较慢的，可以对CRF和指针网络设置不同学习率，或者设置不同的loss权重。</li>
</ul>
</li>
</ul>
<h2 id="trick-10-NER-标注数据噪声问题？"><a href="#trick-10-NER-标注数据噪声问题？" class="headerlink" title="trick 10: NER 标注数据噪声问题？"></a><strong>trick 10: NER 标注数据噪声问题？</strong></h2><ul>
<li>动机：NER 标注数据存在噪声问题，导致模型训练效果差</li>
<li>方法：<ul>
<li>方法一：对训练集进行交叉验证，然后人工去清洗这些“脏数据”</li>
<li>方法二：将noisy label learning应用于NER任务，惩罚那些噪音大的样本loss权重 <strong>【注：具体可以参考 资料12】</strong></li>
</ul>
</li>
</ul>
<h2 id="trick-11：给定两个命名实体识别任务，一个任务数据量足够，另外一个数据量很少，可以怎么做？"><a href="#trick-11：给定两个命名实体识别任务，一个任务数据量足够，另外一个数据量很少，可以怎么做？" class="headerlink" title="trick 11：给定两个命名实体识别任务，一个任务数据量足够，另外一个数据量很少，可以怎么做？"></a><strong>trick 11：给定两个命名实体识别任务，一个任务数据量足够，另外一个数据量很少，可以怎么做？</strong></h2><ul>
<li>动机：NER 标注数据 有些类别 标注数据量 较少；</li>
<li>方法：<ul>
<li>重采样</li>
<li>loss惩罚（Dice loss， Focal Loss）,  以及在颜水成的长尾学习的综述之中大量基于调节logits的做法。</li>
<li>若 该类实体属于 长尾实体（填充率低），可以挖掘相关规则模板、构建词典库</li>
</ul>
</li>
</ul>
<h2 id="trick-12：NER-标注数据不均衡问题？"><a href="#trick-12：NER-标注数据不均衡问题？" class="headerlink" title="trick 12：NER 标注数据不均衡问题？"></a><strong>trick 12：NER 标注数据不均衡问题？</strong></h2><ul>
<li>迁移学习<ul>
<li>假设：数据量足够任务为 T1，数据量很少任务为 T2。</li>
<li>思路<ul>
<li>首先在任务T1中训练模型，然后模型利用之前学习任务所得的知识，应用于任务T2。也就是说模型在任务T1学习知识（特征、权重），然后推广这一知识（特征、权重）至任务T2（明显数据更少）。</li>
</ul>
</li>
</ul>
</li>
<li>半监督策略，即引入虚拟对抗；<ul>
<li>思路：随机生成一个扰动，然后进行导数，L2规范化等处理，生成当前所需要的扰动，将其加入到model原始input embedding，再次求损失；模型最终优化loss + loss（带扰动）;使得模型鲁棒性更强，准确率更高</li>
</ul>
</li>
</ul>

  </div>
</article>


    <div class="blog-post-comments">
        <div id="utterances_thread">
            <noscript>Please enable JavaScript to view the comments.</noscript>
        </div>
    </div>


        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/recording/">Recording</a></li>
         
          <li><a href="/links/">Links</a></li>
         
          <li><a href="/about/">About</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0%E7%AC%94%E8%AE%B0"><span class="toc-number">1.</span> <span class="toc-text">美团技术文章笔记</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%9A%E5%8A%A1%E5%9C%BA%E6%99%AF"><span class="toc-number">1.1.</span> <span class="toc-text">业务场景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B"><span class="toc-number">1.2.</span> <span class="toc-text">技术选型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%8D%E5%85%B8%E6%9E%84%E5%BB%BA"><span class="toc-number">1.3.</span> <span class="toc-text">词典构建</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%95%88%E7%8E%87"><span class="toc-number">1.4.</span> <span class="toc-text">模型效率</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%8E%B7%E5%8F%96"><span class="toc-number">1.5.</span> <span class="toc-text">数据获取</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93%E5%92%8C%E5%B1%95%E6%9C%9B"><span class="toc-number">1.6.</span> <span class="toc-text">总结和展望</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%B3%E4%BA%8E%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%ABTrick-%E7%9A%84%E6%80%BB%E7%BB%93"><span class="toc-number">2.</span> <span class="toc-text">关于实体识别Trick 的总结</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-1%EF%BC%9A%E9%A2%86%E5%9F%9F%E8%AF%8D%E5%85%B8%E5%8C%B9%E9%85%8D"><span class="toc-number">2.1.</span> <span class="toc-text">trick 1：领域词典匹配</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-2%EF%BC%9A%E8%A7%84%E5%88%99%E6%8A%BD%E5%8F%96"><span class="toc-number">2.2.</span> <span class="toc-text">trick 2：规则抽取</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-3%EF%BC%9A%E8%AF%8D%E5%90%91%E9%87%8F%E9%80%89%E5%8F%96%EF%BC%9A%E8%AF%8D%E5%90%91%E9%87%8F-or-%E5%AD%97%E5%90%91%E9%87%8F%EF%BC%9F"><span class="toc-number">2.3.</span> <span class="toc-text">trick 3：词向量选取：词向量 or 字向量？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-4%EF%BC%9A%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E5%99%A8-%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%EF%BC%9F"><span class="toc-number">2.4.</span> <span class="toc-text">trick 4：特征提取器 如何选择？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-5%EF%BC%9A%E4%B8%93%E6%9C%89%E5%90%8D%E7%A7%B0%E6%80%8E%E4%B9%88%E5%A4%84%E7%90%86%EF%BC%9F"><span class="toc-number">2.5.</span> <span class="toc-text">trick 5：专有名称怎么处理？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-6%EF%BC%9A%E6%A0%87%E6%B3%A8%E6%95%B0%E6%8D%AE%E4%B8%8D%E8%B6%B3%E6%80%8E%E4%B9%88%E5%A4%84%E7%90%86%EF%BC%9F"><span class="toc-number">2.6.</span> <span class="toc-text">trick 6：标注数据不足怎么处理？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-7%EF%BC%9A%E5%B5%8C%E5%A5%97%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%80%8E%E4%B9%88%E5%A4%84%E7%90%86-%E3%80%90%E6%B3%A8%EF%BC%9A%E5%8F%82%E8%80%83-%E8%B5%84%E6%96%993%E3%80%91"><span class="toc-number">2.7.</span> <span class="toc-text">trick 7：嵌套命名实体识别怎么处理 【注：参考 资料3】</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-8%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E8%AF%B4-%E3%80%8C%E8%AF%8D%E6%B1%87%E5%A2%9E%E5%BC%BA%E3%80%8D-%E6%96%B9%E6%B3%95%E5%AF%B9%E4%BA%8E%E4%B8%AD%E6%96%87-NER-%E4%BB%BB%E5%8A%A1%E6%9C%89%E6%95%88%EF%BC%9F"><span class="toc-number">2.8.</span> <span class="toc-text">trick 8：为什么说 「词汇增强」 方法对于中文 NER 任务有效？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-9%EF%BC%9ANER%E5%AE%9E%E4%BD%93span%E8%BF%87%E9%95%BF%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F"><span class="toc-number">2.9.</span> <span class="toc-text">trick 9：NER实体span过长怎么办？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-10-NER-%E6%A0%87%E6%B3%A8%E6%95%B0%E6%8D%AE%E5%99%AA%E5%A3%B0%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">2.10.</span> <span class="toc-text">trick 10: NER 标注数据噪声问题？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-11%EF%BC%9A%E7%BB%99%E5%AE%9A%E4%B8%A4%E4%B8%AA%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E4%BB%BB%E5%8A%A1%EF%BC%8C%E4%B8%80%E4%B8%AA%E4%BB%BB%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%87%8F%E8%B6%B3%E5%A4%9F%EF%BC%8C%E5%8F%A6%E5%A4%96%E4%B8%80%E4%B8%AA%E6%95%B0%E6%8D%AE%E9%87%8F%E5%BE%88%E5%B0%91%EF%BC%8C%E5%8F%AF%E4%BB%A5%E6%80%8E%E4%B9%88%E5%81%9A%EF%BC%9F"><span class="toc-number">2.11.</span> <span class="toc-text">trick 11：给定两个命名实体识别任务，一个任务数据量足够，另外一个数据量很少，可以怎么做？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#trick-12%EF%BC%9ANER-%E6%A0%87%E6%B3%A8%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%9D%87%E8%A1%A1%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">2.12.</span> <span class="toc-text">trick 12：NER 标注数据不均衡问题？</span></a></li></ol></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2022/02/18/Notes-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%90%BD%E5%9C%B0%E5%9C%BA%E6%99%AF%E7%9A%84Trick%EF%BC%88%E4%BA%8C%EF%BC%89/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2022/02/18/Notes-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%90%BD%E5%9C%B0%E5%9C%BA%E6%99%AF%E7%9A%84Trick%EF%BC%88%E4%BA%8C%EF%BC%89/&text=Notes-信息抽取落地场景Trick(一)"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2022/02/18/Notes-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%90%BD%E5%9C%B0%E5%9C%BA%E6%99%AF%E7%9A%84Trick%EF%BC%88%E4%BA%8C%EF%BC%89/&title=Notes-信息抽取落地场景Trick(一)"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2022/02/18/Notes-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%90%BD%E5%9C%B0%E5%9C%BA%E6%99%AF%E7%9A%84Trick%EF%BC%88%E4%BA%8C%EF%BC%89/&is_video=false&description=Notes-信息抽取落地场景Trick(一)"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Notes-信息抽取落地场景Trick(一)&body=Check out this article: http://example.com/2022/02/18/Notes-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%90%BD%E5%9C%B0%E5%9C%BA%E6%99%AF%E7%9A%84Trick%EF%BC%88%E4%BA%8C%EF%BC%89/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2022/02/18/Notes-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%90%BD%E5%9C%B0%E5%9C%BA%E6%99%AF%E7%9A%84Trick%EF%BC%88%E4%BA%8C%EF%BC%89/&title=Notes-信息抽取落地场景Trick(一)"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2022/02/18/Notes-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%90%BD%E5%9C%B0%E5%9C%BA%E6%99%AF%E7%9A%84Trick%EF%BC%88%E4%BA%8C%EF%BC%89/&title=Notes-信息抽取落地场景Trick(一)"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2022/02/18/Notes-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%90%BD%E5%9C%B0%E5%9C%BA%E6%99%AF%E7%9A%84Trick%EF%BC%88%E4%BA%8C%EF%BC%89/&title=Notes-信息抽取落地场景Trick(一)"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2022/02/18/Notes-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%90%BD%E5%9C%B0%E5%9C%BA%E6%99%AF%E7%9A%84Trick%EF%BC%88%E4%BA%8C%EF%BC%89/&title=Notes-信息抽取落地场景Trick(一)"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2022/02/18/Notes-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%90%BD%E5%9C%B0%E5%9C%BA%E6%99%AF%E7%9A%84Trick%EF%BC%88%E4%BA%8C%EF%BC%89/&name=Notes-信息抽取落地场景Trick(一)&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2022/02/18/Notes-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%90%BD%E5%9C%B0%E5%9C%BA%E6%99%AF%E7%9A%84Trick%EF%BC%88%E4%BA%8C%EF%BC%89/&t=Notes-信息抽取落地场景Trick(一)"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2016-2023
    yangjing
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a href="/recording/">Recording</a></li><!--
     --><!--
       --><li><a href="/links/">Links</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->
 
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script> 




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script> 
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Umami Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

    <script type="text/javascript">
      var utterances_repo = 'yangjingla/comments';
      var utterances_issue_term = 'pathname';
      var utterances_label = 'Comment';
      var utterances_theme = 'github-light';

      (function(){
          var script = document.createElement('script');

          script.src = 'https://utteranc.es/client.js';
          script.setAttribute('repo', utterances_repo);
          script.setAttribute('issue-term', 'pathname');
          script.setAttribute('label', utterances_label);
          script.setAttribute('theme', utterances_theme);
          script.setAttribute('crossorigin', 'anonymous');
          script.async = true;
          (document.getElementById('utterances_thread')).appendChild(script);
      }());
  </script>

</body>
</html>
